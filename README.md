# Проектирование и обучение нейронных сетей 
Бланк билетов 2025-2026

# Билет 1
<img width="1130" height="451" alt="image" src="https://github.com/user-attachments/assets/f9c48634-2413-49a6-992b-66345a1cddfd" />

**Ответ на вопрос 1**

**Понятие о математическом нейроне. Биологический прототип. Искусственный (математический) нейрон. Использование нейронной сети.**

**Биологический прототип.**  
Математический нейрон является упрощенной моделью биологического нейрона — основной структурной единицы нервной системы. Биологический нейрон состоит из тела (сомы), дендритов (принимают сигналы) и аксона (передает сигналы). Нейроны обмениваются электрохимическими сигналами через синапсы. При превышении суммарного возбуждения порогового значения нейрон генерирует импульс.

**Искусственный (математический) нейрон.**  
Математический нейрон формализует работу биологического нейрона. Он имеет:
- Входы \( x_1, x_2, ..., x_n \), соответствующие дендритам.
- Веса \( w_1, w_2, ..., w_n \), моделирующие силу синаптических связей.
- Сумматор, вычисляющий взвешенную сумму входов:  
<img width="202" height="105" alt="image" src="https://github.com/user-attachments/assets/c10dcd4c-159e-456e-81e0-4ac89782e197" />

- Пороговую функцию активации (например, функцию Хевисайда), которая сравнивает сумму \( S \) с порогом \( \theta \):
<img width="306" height="126" alt="image" src="https://github.com/user-attachments/assets/d8d9fe05-edc1-435c-ab32-dccdf01620b6" />

  Это соответствует переходу нейрона в возбужденное состояние при достаточной суммарной стимуляции.

**Использование нейронной сети.**  
Нейронные сети, состоящие из множества математических нейронов, используются для решения задач классификации образов, распознавания образов, прогнозирования и других задач, связанных с обработкой данных. Они моделируют простые свойства биологических нейронов, такие как суммирование входных сигналов и пороговая активация, но не копируют биологические процессы детально.

Простота математического нейрона позволяет легко его реализовывать и комбинировать в сложные структуры (сети), которые демонстрируют способность к обучению и обобщению на основе данных.

**Ответ на вопрос 2**

**Рекуррентные сети. Вентильные рекуррентные нейронные сети. Долгая краткосрочная память.**

**Рекуррентные сети (РНС)** — это класс нейронных сетей, предназначенных для обработки последовательностей данных, где порядок элементов важен (речь, текст, временные ряды). Их ключевая особенность — наличие обратных связей, позволяющих сохранять информацию о предыдущих состояниях сети. Это делает их пригодными для задач, где контекст и история влияют на текущий результат.

**Долгая краткосрочная память (LSTM)** — это особый тип рекуррентной сети, разработанный для решения проблемы исчезающего градиента и улавливания долгосрочных зависимостей в данных. LSTM включает в себя **вентильные механизмы**:
- **Входной вентиль** — решает, какую новую информацию записать в состояние ячейки.
- **Вентиль забывания** — определяет, какую информацию из состояния ячейки следует удалить.
- **Выходной вентиль** — управляет тем, какая информация из состояния ячейки будет использована для формирования выходного сигнала.

Благодаря этим вентилям LSTM может избирательно сохранять или забывать информацию на длительных промежутках времени, что делает её эффективной для задач машинного перевода, распознавания речи, анализа текстов и других последовательностных задач.

**Вентильные рекуррентные нейронные сети (GRU)** — это упрощённая версия LSTM, в которой объединены вентиль забывания и входной вентиль в один **вентиль обновления**. GRU имеет меньше параметров, чем LSTM, и часто показывает сопоставимую производительность, обучаясь быстрее.

Таким образом, рекуррентные сети, особенно их вентильные варианты (LSTM и GRU), являются мощным инструментом для работы с последовательными данными, где требуется учёт контекста и долгосрочных зависимостей.

**Ответ на вопрос 3**

**Архитектуры сверточных сетей. Сети ResNet.**

Сверточные нейронные сети (СНС) — это глубокие нейронные сети, специально разработанные для обработки данных с сеточной структурой, таких как изображения. Их архитектура включает последовательность сверточных слоёв, слоёв подвыборки (пулинга) и полносвязных слоёв.

**Основные компоненты архитектуры СНС:**
1.  **Свёрточные слои** – применяют фильтры (ядра) к входным данным для извлечения локальных признаков (например, границ, текстур). Используется **разделение параметров** (один фильтр применяется ко всему изображению) и **разреженная связность** (каждый нейрон связан только с локальной областью предыдущего слоя).
2.  **Слои подвыборки (пулинга)** – уменьшают пространственные размеры карт признаков, сохраняя наиболее важную информацию, повышая инвариантность к малым сдвигам и сокращая объём вычислений.
3.  **Полносвязные слои** – располагаются в конце сети и выполняют классификацию на основе извлечённых признаков.

**Проблема исчезающего градиента в очень глубоких сетях:**  
С увеличением глубины сети (количества слоёв) процесс обучения становится сложнее из-за проблемы исчезающего градиента, когда градиенты, распространяемые обратно, становятся чрезвычайно малы, и веса нижних слоёв почти не обновляются. Это ограничивает глубину обучаемых сетей.

**Сети ResNet (Residual Networks):**  
Для решения проблемы исчезающего градиента были предложены сети **ResNet** (сети с остаточными связями). Их ключевая инновация — использование **остаточных блоков (residual blocks)**. Вместо обучения прямой функции отображения \( H(x) \) бло́к обучает **остаточную функцию** \( F(x) = H(x) - x \), а итоговое отображение получается как \( H(x) = F(x) + x \).

**Структура остаточного блока:**  
Входные данные \( x \) пропускаются по **прямой связи (skip connection)** и суммируются с результатом преобразования \( F(x) \), полученного после нескольких свёрточных слоёв. Это позволяет градиенту свободно протекать через эти связи, даже если преобразование \( F(x) \) близко к нулю, что облегчает обучение чрезвычайно глубоких сетей (например, ResNet-152 с 152 слоями).

Таким образом, архитектура ResNet, основанная на остаточных связях, стала прорывом в области глубокого обучения, позволив эффективно обучать очень глубокие свёрточные сети и достигать высоких результатов в задачах компьютерного зрения, таких как классификация, обнаружение и сегментация объектов.

# Билет 2

<img width="1116" height="445" alt="image" src="https://github.com/user-attachments/assets/927c69db-9bb5-4999-b721-0ea12fa51508" />

**Ответ на вопрос 1**

**Математический нейрон Мак1Каллока – Питтса. Схематичное изображение. Активационная (пороговая) функция. Пример расчета с порогом логическое «И»**

Математический нейрон Мак-Каллока – Питтса представляет собой формальную модель нейрона с несколькими входами и одним выходом. Каждому входу соответствует вес, а выход определяется на основе пороговой функции активации.

**Схематичное изображение**:
Нейрон включает:
- Входные сигналы \(x_1, x_2, ..., x_n\).
- Веса \(w_1, w_2, ..., w_n\).
- Сумматор, вычисляющий взвешенную сумму:
<img width="215" height="119" alt="image" src="https://github.com/user-attachments/assets/79d98e11-f71e-4fcc-8fee-aa97a5996cbf" />

- Пороговую функцию активации (функцию Хевисайда), которая сравнивает сумму \(S\) с порогом \(T\):
<img width="357" height="125" alt="image" src="https://github.com/user-attachments/assets/e10aac11-b947-4b61-922e-bce59f9cd441" />


**Пример расчета логического «И»**:
Для реализации логического «И» с двумя входами \(x_1\) и \(x_2\) (принимающих значения 0 или 1) используются веса \(w_1 = 1\), \(w_2 = 1\) и порог \(T = 2\).

Расчеты:
1. \(x_1 = 0, x_2 = 0 \rightarrow S = 0 \cdot 1 + 0 \cdot 1 = 0; \quad y = 0\)
2. \(x_1 = 0, x_2 = 1 \rightarrow S = 0 \cdot 1 + 1 \cdot 1 = 1; \quad y = 0\)
3. \(x_1 = 1, x_2 = 0 \rightarrow S = 1 \cdot 1 + 0 \cdot 1 = 1; \quad y = 0\)
4. \(x_1 = 1, x_2 = 1 \rightarrow S = 1 \cdot 1 + 1 \cdot 1 = 2; \quad y = 1\)

Результат соответствует таблице истинности логического «И»: выход равен 1 только при обоих единичных входах.

**Ответ на вопрос 2**

**Рекуррентные сети. Двунаправленные рекуррентные нейронные сети. Блоки с утечками.**

**Рекуррентные сети (РНС)** — это нейронные сети, имеющие обратные связи, позволяющие сохранять информацию о предыдущих состояниях. Они применяются для обработки последовательностей данных (речь, текст, временные ряды), где порядок элементов важен. Примеры: сеть Элмана (Simple RNN), LSTM (Long Short-Term Memory), GRU (Gated Recurrent Unit). Обучение РНС часто проводится методом обратного распространения во времени (Backpropagation Through Time, BPTT).

**Двунаправленные рекуррентные нейронные сети (Bi‑RNN)** используются, когда для предсказания в момент времени \(t\) важна информация не только из прошлого, но и из будущего. Bi‑RNN состоят из двух независимых РНС: одна обрабатывает последовательность в прямом направлении (от начала к концу), другая — в обратном (от конца к началу). Выходы обеих сетей на каждом шаге объединяются (например, конкатенируются или суммируются), что позволяет учитывать контекст со всех сторон. Такие сети эффективны в задачах распознавания речи, машинного перевода, анализа текста.

**Блоки с утечками (Leaky Units)** — это способ улучшить способность РНС запоминать долгосрочные зависимости. Вместо полного обновления скрытого состояния на каждом шаге используется линейная комбинация старого и нового состояний:
<img width="508" height="80" alt="image" src="https://github.com/user-attachments/assets/9764fb66-3bc3-4735-9342-a87071f8a322" />

где \(\alpha\) — параметр «утечки» (близкий к 1). Это позволяет информации сохраняться на много шагов, аналогично экспоненциальному скользящему среднему. Блоки с утечками являются упрощённой альтернативой более сложным механизмам вроде LSTM и помогают бороться с проблемой затухания градиента.

**Ответ на вопрос 3**

**Архитектуры сверточных сетей. Архитектура Inception. Общая схема сети GoogLeNet**

**Архитектуры сверточных сетей** строятся на основе последовательного чередования сверточных слоёв, слоёв пулинга (объединения) и полносвязных слоёв. Сверточные слои извлекают локальные признаки (границы, текстуры), а пулинг-слои уменьшают пространственные размеры, повышая инвариантность к малым сдвигам и деформациям. Глубокие свёрточные сети (такие как VGG, ResNet) позволяют выделять иерархические признаки: от простых на начальных слоях до сложных, семантических — на последующих.

**Архитектура Inception** (также известная как **GoogLeNet**) была предложена для повышения эффективности и глубины сети без чрезмерного роста вычислительной сложности. Её ключевая идея — использование **Inception-модулей**, которые параллельно применяют несколько типов свёрток (1×1, 3×3, 5×5) и операцию пулинга к одному и тому же входу, а затем объединяют их результаты. Это позволяет сети одновременно извлекать признаки разного масштаба и уровня абстракции.

**Общая схема сети GoogLeNet** включает:
1. Начальные свёрточные слои для первичной обработки изображения.
2. Последовательность **Inception-модулей**, каждый из которых состоит из параллельных ветвей:
   - Свёртка 1×1 (для уменьшения размерности и снижения вычислений).
   - Свёртка 3×3.
   - Свёртка 5×5.
   - Максимальный пулинг 3×3 с последующей свёрткой 1×1.
   Все выходы ветвей объединяются по глубине (конкатенация).
3. Вспомогательные классификаторы на промежуточных слоях для борьбы с исчезающим градиентом и улучшения обучения.
4. Глобальный средний пулинг вместо полносвязных слоёв в конце, что уменьшает число параметров.
5. Финальный классификационный слой с функцией Softmax.

Таким образом, GoogLeNet демонстрирует, как можно эффективно комбинировать операции разного масштаба в рамках одного модуля, создавая глубокие и мощные сети для задач компьютерного зрения.

# Билет 3

<img width="1129" height="452" alt="image" src="https://github.com/user-attachments/assets/0b55c307-4e1b-4464-87fd-3d6304f7f6e5" />

**Ответ на вопрос 1**

**Математический нейрон Мак-Каллока – Питтса. Схематичное изображение. Активационная (пороговая) функция. Пример расчета с порогом логическое «ИЛИ»**

Математический нейрон Мак-Каллока – Питтса — это формальная модель нейрона, состоящая из нескольких входов, весов, сумматора и пороговой функции активации.

**Схематичное изображение**:
- Входы: \( x_1, x_2, ..., x_n \)
- Веса: \( w_1, w_2, ..., w_n \)
- Сумматор вычисляет взвешенную сумму:
<img width="202" height="113" alt="image" src="https://github.com/user-attachments/assets/624a4315-07c2-4f5d-8d27-cc82fda609bf" />

- Пороговая функция активации (функция Хевисайда) определяет выход:
<img width="337" height="127" alt="image" src="https://github.com/user-attachments/assets/886008b1-18ec-4fca-a658-ed6cb0eb73c9" />

  где \( T \) — порог чувствительности нейрона.

**Пример расчета логического «ИЛИ»**:
Для реализации логического «ИЛИ» с двумя входами \( x_1 \) и \( x_2 \) (принимающих значения 0 или 1) используются веса \( w_1 = 1 \), \( w_2 = 1 \) и порог \( T = 1 \).

Расчеты:
1. \( x_1 = 0, x_2 = 0 \rightarrow S = 0 \cdot 1 + 0 \cdot 1 = 0; \quad y = 0 \)
2. \( x_1 = 0, x_2 = 1 \rightarrow S = 0 \cdot 1 + 1 \cdot 1 = 1; \quad y = 1 \)
3. \( x_1 = 1, x_2 = 0 \rightarrow S = 1 \cdot 1 + 0 \cdot 1 = 1; \quad y = 1 \)
4. \( x_1 = 1, x_2 = 1 \rightarrow S = 1 \cdot 1 + 1 \cdot 1 = 2; \quad y = 1 \)

Результат соответствует таблице истинности логического «ИЛИ»: выход равен 1, если хотя бы один вход равен 1.

**Ответ на вопрос 2**

**Рекуррентные сети. Метод обучения рекуррентной нейронной сети. Функция softmax.**

**Рекуррентные сети (RNN)** — это нейронные сети, в которых присутствуют обратные связи, позволяющие сохранять информацию о предыдущих состояниях. Они предназначены для обработки последовательных данных, где порядок элементов важен (например, речь, текст, временные ряды). Примеры архитектур: сеть Элмана, сеть Хопфилда, LSTM, GRU. RNN могут иметь различные конфигурации: «один ко многим», «многие к одному», «многие ко многим».

**Метод обучения рекуррентной нейронной сети** — **BPTT (Backpropagation Through Time)**.  
Так как RNN работают с последовательностями во времени, стандартный метод обратного распространения ошибки модифицируется. Идея BPTT заключается в «разворачивании» сети во времени: каждый шаг последовательности представляется как отдельный слой в глубокой сети. Градиент ошибки вычисляется для каждого временного шага и распространяется назад по развернутой структуре. Это позволяет учитывать зависимости между удаленными во времени элементами последовательности, но требует больших вычислительных ресурсов и памяти порядка O(τ), где τ — длина последовательности.

**Функция softmax** — это активационная функция, применяемая на выходном слое сети для задач многоклассовой классификации. Она преобразует вектор произвольных значений (логитов) в вектор вероятностей, где сумма всех элементов равна 1. Формула softmax для элемента \( z_i \):

<img width="265" height="102" alt="image" src="https://github.com/user-attachments/assets/5b44db27-6434-4ca8-b145-9a073fa4d12b" />


где \( K \) — количество классов.  
Функция гарантирует, что выходные значения интерпретируются как вероятности принадлежности объекта к каждому классу. Часто используется в сочетании с функцией потерь «перекрестная энтропия» для обучения классификаторов, в том числе в рекуррентных сетях для задач последовательной классификации (например, предсказание следующего слова).

**Ответ на вопрос 3**

**Архитектура сверточных сетей. Схема сети VGG-16.**

**Архитектура сверточных сетей (CNN)** строится на основе последовательного чередования сверточных слоёв (Conv), слоёв подвыборки (пулинга, Pooling) и полносвязных слоёв (FC).  
- **Сверточный слой** применяет набор фильтров (ядер) к входному изображению, извлекая локальные признаки (границы, текстуры и т.д.).  
- **Слой подвыборки (пулинг)** уменьшает пространственные размеры карт признаков, сохраняя наиболее значимую информацию и снижая вычислительную сложность. Часто используется max-pooling.  
- **Полносвязные слои** в конце сети выполняют классификацию на основе извлечённых признаков.

**Сеть VGG-16** — одна из классических глубоких сверточных архитектур, предложенная в 2014 году. Её ключевые особенности:  
- Состоит из **16 весовых слоёв** (13 свёрточных и 3 полносвязных).  
- Использует **маленькие фильтры 3×3** с шагом 1, что позволяет уменьшить количество параметров по сравнению с большими фильтрами, при этом увеличивая глубину сети и её нелинейность.  
- Все скрытые слои используют **функцию активации ReLU**.  
- После нескольких свёрточных слоёв применяется **max-pooling с окном 2×2 и шагом 2**, уменьшающий размер карт признаков вдвое.  
- Архитектура включает **три полносвязных слоя** (два скрытых по 4096 нейронов и выходной слой с 1000 нейронов для классификации ImageNet).  
- Входное изображение имеет размер **224×224×3** (RGB).

**Схема VGG-16** (упрощённо):  
1. Conv3-64 → Conv3-64 → MaxPool  
2. Conv3-128 → Conv3-128 → MaxPool  
3. Conv3-256 → Conv3-256 → Conv3-256 → MaxPool  
4. Conv3-512 → Conv3-512 → Conv3-512 → MaxPool  
5. Conv3-512 → Conv3-512 → Conv3-512 → MaxPool  
6. FC-4096 → FC-4096 → FC-1000 (Softmax)

Основные преимущества VGG-16 — однородность архитектуры и хорошая обобщающая способность, хотя она требует больших вычислительных ресурсов из-за значительного числа параметров.

# Билет 4

<img width="1111" height="452" alt="image" src="https://github.com/user-attachments/assets/3c85d9a2-c4e8-45d9-b403-24e66e29587a" />

**Ответ на вопрос 1**

**Математический нейрон Мак-Каллока – Питтса. Схематичное изображение. Активационная (пороговая) функция. Пример расчета со смещением логическое «ИЛИ». Графическая интерпретация**

**Схематичное изображение математического нейрона**  
Математический нейрон состоит из:
- Входных сигналов \(x_1, x_2, ..., x_n\)
- Весов \(w_1, w_2, ..., w_n\)
- Сумматора, вычисляющего взвешенную сумму:  
 <img width="260" height="126" alt="image" src="https://github.com/user-attachments/assets/c577177e-8100-49c8-9df5-9bcb0c02ebe2" />

  где \(b\) – смещение (bias), эквивалентное весу дополнительного входа \(x_0 = 1\).
- Пороговой функции активации (функция Хевисайда), определяющей выход:  
<img width="313" height="115" alt="image" src="https://github.com/user-attachments/assets/21376e10-ff21-429b-8008-c7d3ca285bda" />


**Пример расчета логического «ИЛИ» со смещением**  
Для реализации логического «ИЛИ» с двумя входами \(x_1, x_2\) (значения 0 или 1) выбираются веса \(w_1 = 1, w_2 = 1\) и смещение \(b = -0.5\) (эквивалентно порогу \(T = 0.5\), так как \(b = -T\)).

Расчет взвешенной суммы \(S\) для всех комбинаций входов:
1. \(x_1 = 0, x_2 = 0\):  
   \(S = 0\cdot1 + 0\cdot1 + (-0.5) = -0.5\) → \(y = 0\)
2. \(x_1 = 0, x_2 = 1\):  
   \(S = 0\cdot1 + 1\cdot1 + (-0.5) = 0.5\) → \(y = 1\)
3. \(x_1 = 1, x_2 = 0\):  
   \(S = 1\cdot1 + 0\cdot1 + (-0.5) = 0.5\) → \(y = 1\)
4. \(x_1 = 1, x_2 = 1\):  
   \(S = 1\cdot1 + 1\cdot1 + (-0.5) = 1.5\) → \(y = 1\)

Результат соответствует таблице истинности логического «ИЛИ».

**Графическая интерпретация**  
В пространстве входов \((x_1, x_2)\) разделяющая гиперплоскость задается уравнением:

w_1 x_1 + w_2 x_2 + b = 0

Подставляя \(w_1 = 1, w_2 = 1, b = -0.5\), получаем:

x_1 + x_2 - 0.5 = 0 \quad \Rightarrow \quad x_1 + x_2 = 0.5

Эта прямая разделяет точки \((0,0)\) (класс 0) от точек \((0,1), (1,0), (1,1)\) (класс 1). Все точки, для которых \(x_1 + x_2 \geq 0.5\), классифицируются как 1, что соответствует логическому «ИЛИ».

**Ответ на вопрос 2**

**Рекуррентные сети. Глубокие рекуррентные нейронные сети.**

**Рекуррентные сети** — это класс нейронных сетей, предназначенных для обработки последовательностей данных, где порядок элементов важен. Они обладают внутренней памятью, так как нейроны имеют обратные связи, позволяющие сохранять информацию о предыдущих состояниях. Это делает их пригодными для задач, где контекст и временные зависимости играют ключевую роль: распознавание речи, обработка естественного языка, машинный перевод и т.д.

**Глубокие рекуррентные нейронные сети** представляют собой усложнённые архитектуры рекуррентных сетей, в которых преобразования между слоями или внутри скрытых состояний выполняются многослойно. Это позволяет моделировать более сложные и долгосрочные зависимости. Примеры таких архитектур:

1. **Глубокая рекуррентная сеть с глубоким преобразованием входа (Deep Transition RNN, DT-RNN)** — использует несколько слоёв для преобразования входного сигнала в скрытое состояние на каждом шаге.
2. **Глубокая рекуррентная сеть с глубоким преобразованием выхода (Deep Output RNN, DO-RNN)** — применяет глубокие преобразования между скрытым состоянием и выходом.
3. **Стек рекуррентных сетей** — состоит из нескольких рекуррентных слоёв, где выход одного слоя является входом для следующего, что увеличивает выразительную способность сети.

Для обучения рекуррентных сетей часто используется метод **обратного распространения во времени (Backpropagation Through Time, BPTT)**, который разворачивает сеть во времени и применяет алгоритм обратного распространения ошибки к развёрнутой структуре.

**Ответ на вопрос 3**

**Реализация сверточных сетей. Обучение. Пример выделения признаков на двух сверточных слоях.**

**Реализация и обучение сверточных сетей (СНС)**  
Сверточные нейронные сети реализуются как последовательность слоёв, основными из которых являются:
1. **Сверточные слои** — применяют фильтры (ядра) к входным данным, выделяя локальные признаки. Каждый фильтр скользит по изображению с заданным шагом, вычисляя свёртку.
2. **Слои активации** — добавляют нелинейность (часто ReLU).
3. **Слои пулинга (подвыборки)** — уменьшают размерность карт признаков, сохраняя важную информацию (макс-пулинг, средний пулинг).
4. **Полносвязные слои** — выполняют классификацию на основе выделенных признаков.

**Обучение СНС** происходит с помощью метода обратного распространения ошибки (backpropagation) и градиентного спуска. Функция потерь (например, кросс-энтропия) минимизируется путём обновления весов фильтров и полносвязных слоёв. Для ускорения обучения используются оптимизаторы (Adam, SGD) и методы регуляризации (Dropout, Batch Normalization).

**Пример выделения признаков на двух сверточных слоях**  
Рассмотрим простую архитектуру для обработки изображений:

1. **Первый сверточный слой**:
   - Применяет несколько фильтров небольшого размера (например, 3×3).
   - Выделяет низкоуровневые признаки: границы, углы, текстуры.
   - После свертки применяется активация ReLU для нелинейности.
   - Затем выполняется макс-пулинг для уменьшения размерности.

2. **Второй сверточный слой**:
   - Принимает карты признаков от первого слоя.
   - Использует фильтры большего количества и/или размера.
   - Выделяет более сложные и абстрактные признаки: комбинации границ, простые формы, паттерны.
   - Снова применяется ReLU и пулинг.

Таким образом, первый слой отвечает за обнаружение простых локальных особенностей, а второй — за их комбинирование в более сложные структуры. Это соответствует иерархическому принципу обработки информации в зрительной коре мозга и позволяет сети эффективно распознавать объекты на изображениях.

# Билет 5

<img width="1096" height="473" alt="image" src="https://github.com/user-attachments/assets/b1606604-8d5a-4be1-bef8-54700620f145" />

**Ответ на вопрос 1**

**Математический нейрон Мак-Каллока – Питтса. Схематичное изображение. Активационная (пороговая) функция. Пример расчета со смещением логическое «И». Графическая интерпретация.**

**Схематичное изображение математического нейрона:**  
Нейрон включает:
- Входы: \(x_1, x_2, ..., x_n\)  
- Веса: \(w_1, w_2, ..., w_n\)  
- Сумматор вычисляет взвешенную сумму с учётом смещения \(b\):  
<img width="262" height="99" alt="image" src="https://github.com/user-attachments/assets/e9fc773b-2a67-4e50-9217-dfd64cdebe14" />

- Пороговая функция активации (функция Хевисайда) определяет выход:  
<img width="305" height="117" alt="image" src="https://github.com/user-attachments/assets/3c86d07d-6796-48e0-8ecf-142dd1a1e073" />

Здесь смещение \(b\) эквивалентно весу дополнительного входа \(x_0 = 1\) и позволяет сдвигать порог активации.

**Пример расчета логического «И» со смещением:**  
Для двух входов \(x_1, x_2\) (значения 0 или 1) выбираем веса \(w_1 = 1, w_2 = 1\) и смещение \(b = -1.5\) (что соответствует порогу \(T = 1.5\), так как \(b = -T\)).

Рассчитываем взвешенную сумму \(S\) для всех комбинаций входов:

1. \(x_1 = 0, x_2 = 0\):  
   \(S = 0 \cdot 1 + 0 \cdot 1 + (-1.5) = -1.5\) → \(y = 0\)  
2. \(x_1 = 0, x_2 = 1\):  
   \(S = 0 \cdot 1 + 1 \cdot 1 + (-1.5) = -0.5\) → \(y = 0\)  
3. \(x_1 = 1, x_2 = 0\):  
   \(S = 1 \cdot 1 + 0 \cdot 1 + (-1.5) = -0.5\) → \(y = 0\)  
4. \(x_1 = 1, x_2 = 1\):  
   \(S = 1 \cdot 1 + 1 \cdot 1 + (-1.5) = 0.5\) → \(y = 1\)

Результат соответствует таблице истинности логического «И»: выход равен 1 только когда оба входа равны 1.

**Графическая интерпретация:**  
В пространстве входов \((x_1, x_2)\) разделяющая гиперплоскость задаётся уравнением:  

w_1 x_1 + w_2 x_2 + b = 0

Подставляя \(w_1 = 1, w_2 = 1, b = -1.5\), получаем:  

x_1 + x_2 - 1.5 = 0 \quad \Rightarrow \quad x_1 + x_2 = 1.5

Эта прямая разделяет точку \((1,1)\) (класс 1) от остальных точек \((0,0), (0,1), (1,0)\) (класс 0). Только для точки \((1,1)\) выполняется условие \(x_1 + x_2 \geq 1.5\), что соответствует логической функции «И».

**Ответ на вопрос 2**

**Рекуррентные сети. Сеть Элмана. Схема и общий вид нейронной сети Элмана. Модификации схемы работы сети Элмана.**

**Рекуррентные сети** – это класс нейронных сетей, в которых между элементами существуют обратные связи, позволяющие сохранять информацию о предыдущих состояниях. Они используются для обработки последовательных данных (речь, текст, временные ряды), где порядок элементов важен.

**Сеть Элмана** (Simple Recurrent Network, SRN) – одна из базовых архитектур рекуррентных сетей. Она состоит из трёх слоёв:
1. **Входной слой** – принимает входной вектор в момент времени \( t \).
2. **Скрытый слой** – содержит нейроны с обратными связями на самих себя, что позволяет сохранять информацию о предыдущих состояниях сети.
3. **Выходной слой** – формирует выходной сигнал.

**Общий вид сети Элмана** описывается следующими уравнениями:
<img width="418" height="140" alt="image" src="https://github.com/user-attachments/assets/d313aa94-ab83-40bd-b209-7e077e66e8c3" />

где:
- \( h^{(t)} \) – состояние скрытого слоя в момент \( t \),
- \( x^{(t)} \) – входной вектор,
- \( y^{(t)} \) – выходной вектор,
- \( U, W, V \) – матрицы весов,
- \( b, c \) – смещения,
- \( f, g \) – функции активации.

**Схема сети Элмана** включает прямые связи от входа к скрытому слою и от скрытого слоя к выходу, а также рекуррентные связи внутри скрытого слоя, передающие состояние \( h^{(t-1)} \) на следующий шаг.

**Модификации схемы работы сети Элмана**:
1. **Архитектура «много в один» (many-to-one)** – несколько входных шагов преобразуются в один выход (например, классификация последовательности).
2. **Архитектура «один во много» (one-to-many)** – один вход преобразуется в последовательность выходов (например, генерация текста).
3. **Архитектура «много во много» (many-to-many)** – последовательность на входе преобразуется в последовательность на выходе (машинный перевод, обработка речи).

Для обучения сети Элмана используется модифицированный метод обратного распространения ошибки во времени (Backpropagation Through Time, BPTT), который разворачивает рекуррентную сеть в глубокую сеть прямого распространения по временным шагам.

**Ответ на вопрос 3**

**Реализация сверточных сетей. Выбор максимального значения из соседних. Пример max-пулинга. Инвариантность.**

Сверточные нейронные сети (СНС) реализуются с использованием последовательности **сверточных слоёв** и **слоёв подвыборки (пулинга)**.  

**Max-пулинг** — это операция подвыборки, которая уменьшает пространственные размеры карты признаков, сохраняя наиболее значимые признаки. На каждом шаге окно фиксированного размера (например, 2×2) скользит по карте признаков, и в выход записывается **максимальное значение** из элементов, попавших в это окно.

**Пример max-пулинга**:  
Для входной матрицы 4×4:  

<img width="191" height="164" alt="image" src="https://github.com/user-attachments/assets/173eb921-68c3-42c2-99d1-693963438236" />

Применяем окно 2×2 с шагом 2. Получаем:  
- В первом окне (1, 3; 4, 2) максимум = 4  
- Во втором окне (2, 1; 7, 3) максимум = 7  
- В третьем окне (3, 5; 2, 6) максимум = 6  
- В четвёртом окне (1, 2; 4, 8) максимум = 8  

Итоговая матрица 2×2:  
<img width="116" height="99" alt="image" src="https://github.com/user-attachments/assets/c9b828d2-f810-40b1-9455-d8e335390ba2" />


**Инвариантность**, обеспечиваемая max-пулингом:  
- **Пространственная инвариантность к малым сдвигам и искажениям**: поскольку выбирается максимальное значение в окне, сеть становится менее чувствительной к точному расположению признаков.  
- **Уменьшение переобучения**: снижение размерности сокращает количество параметров и вычислительную сложность.  
- **Сохранение наиболее ярко выраженных признаков**: активированные нейроны с наибольшими значениями передаются на следующий слой, что помогает выделять существенные особенности.

Таким образом, max-пулинг является важным компонентом сверточных сетей, обеспечивающим инвариантность к пространственным изменениям и повышающим эффективность обучения.

# Билет 6

<img width="1100" height="452" alt="image" src="https://github.com/user-attachments/assets/92a68a1c-7873-4b62-81aa-37c6bf6765e5" />

**Ответ на вопрос 1**

**Понятие о математическом нейроне.**  
Математический нейрон — это упрощенная модель биологического нейрона, формализующая процесс обработки сигнала. Он состоит из:
- Входных сигналов \(x_1, x_2, ..., x_n\),
- Весов \(w_1, w_2, ..., w_n\),
- Сумматора, вычисляющего взвешенную сумму:
<img width="276" height="114" alt="image" src="https://github.com/user-attachments/assets/c131c574-0184-470e-ad6f-184878a69ad4" />

  где \(b\) — смещение,
- Активационной функции, преобразующей сумму \(S\) в выходной сигнал \(y\).

**Активационная функция** определяет нелинейное преобразование, позволяющее нейрону решать сложные задачи. Её выбор влияет на способность сети к обучению.

**Сигмоидальная функция (логистическая функция):**  
<img width="233" height="96" alt="image" src="https://github.com/user-attachments/assets/bdd53ee7-c2dc-4286-8cd0-11049e76db12" />

Она «сжимает» вход в диапазон \((0, 1)\), что удобно для интерпретации выхода как вероятности. Производная выражается через саму функцию: \(\sigma'(x) = \sigma(x)(1 - \sigma(x))\), что упрощает обратное распространение ошибки.

**Гиперболический тангенс:**  
<img width="297" height="103" alt="image" src="https://github.com/user-attachments/assets/835a1d57-edaa-46e7-9a8b-b8470161912a" />

Принимает значения в диапазоне \((-1, 1)\), центрируя данные, что часто ускоряет сходимость обучения.

**Линейная функция активации:**  

f(x) = cx

Пропорциональна входу, позволяет получать непрерывный спектр значений. Однако её производная постоянна, что затрудняет обучение в глубоких сетях, так как композиция линейных функций остаётся линейной.

**Полулинейный элемент (ReLU — Rectified Linear Unit):**  
<img width="247" height="66" alt="image" src="https://github.com/user-attachments/assets/6537f1d1-3f6c-4822-b3b8-f8a0f9619778" />

Возвращает \(x\), если \(x > 0\), и 0 в противном случае. ReLU нелинейна, вычислительно эффективна, способствует разреженной активации, но может страдать от проблемы «умирающих нейронов» при нулевом градиенте для отрицательных входов.

**Ответ на вопрос 2**

**Сети встречного распространения. Обучение слоя Кохонена. Предварительная обработка входных векторов. Выбор начальных значений весовых векторов.**

**Сети встречного распространения** — это гибридная архитектура, объединяющая **самоорганизующуюся карту Кохонена** (первый слой) и **звезду Гроссберга** (второй слой). Они работают как «стол справок», обучаясь ассоциировать входные векторы с выходными. Сеть способна к обобщению, выдавая правильный выход даже при неполном или искаженном входе.

**Обучение слоя Кохонена** происходит **без учителя** по принципу «победитель получает все». Для входного вектора вычисляются скалярные произведения с весовыми векторами всех нейронов Кохонена. Нейрон с максимальным значением (наиболее близкий к входу) объявляется победителем. Его веса корректируются по правилу:
<img width="471" height="60" alt="image" src="https://github.com/user-attachments/assets/1e335f99-c022-4f10-817e-96452ca88c22" />

где \(\alpha\) — коэффициент скорости обучения (\(0 < \alpha < 1\)). Корректировка приближает веса победившего нейрона к входному вектору.

**Предварительная обработка входных векторов** включает их **нормировку** (приведение к единичной длине). Вектор \(X\) нормируется так, чтобы его длина в \(n\)-мерном пространстве была равна 1. Это необходимо для корректной работы слоя Кохонена, так как процесс обучения основан на сравнении направлений (скалярном произведении), а не абсолютных величин.

**Выбор начальных значений весовых векторов** — критический этап. Идеально распределить их в соответствии с плотностью входных данных. Один из практических методов — **метод выпуклой комбинации (convex combination method)**. Изначально все веса устанавливаются равными \(1/\sqrt{n}\) (где \(n\) — число входов), что делает их единичными. Входные компоненты модифицируются как:
<img width="244" height="95" alt="image" src="https://github.com/user-attachments/assets/8ecd47f1-eef0-4cb0-b783-9a5197cb4ebe" />

В начале обучения параметр \(a\) мал, и входные векторы близки к весовым. По мере обучения \(a\) постепенно увеличивается до 1, что позволяет сети разделить классы входных векторов и закрепить их за конкретными нейронами Кохонена.

**Ответ на вопрос 3**

**Сверточные сети. Операция свертки. Пример двумерной свертки. Эффекты границ, дополнение и шаг свертки.**

**Сверточные нейронные сети (СНС)** — это специальный вид нейронных сетей, предназначенных для обработки данных с сеточной структурой, таких как изображения. Они вдохновлены организацией зрительной коры мозга и обладают ключевыми свойствами: **инвариантность к переносу**, **разреженная связность** и **разделение параметров**.

**Операция свертки** — это линейное преобразование входных данных с помощью **ядра** (фильтра). Для двумерного случая (изображение) она вычисляется как взвешенная сумма пикселей в локальной области:

<img width="432" height="126" alt="image" src="https://github.com/user-attachments/assets/17f5f771-c80b-42af-bf22-3079e831c464" />


где:
- \(x\) — входная карта признаков (изображение),
- \(W\) — ядро свертки размера \((2d+1) \times (2d+1)\),
- \(y_{i,j}\) — выходное значение в позиции \((i,j)\).

**Пример двумерной свертки**:  
Если входное изображение имеет размер \(5 \times 5\), а ядро — \(3 \times 3\), то выходная карта признаков будет размером \(3 \times 3\) (без дополнения). Каждый элемент выходной карты вычисляется как сумма произведений элементов ядра на соответствующий фрагмент входного изображения.

**Эффекты границ, дополнение и шаг свертки**:
- **Эффекты границ**: при свертке без дополнения размер выходной карты уменьшается. Например, для входа \(m \times m\) и ядра \(k \times k\) выход будет \((m-k+1) \times (m-k+1)\).
- **Дополнение (padding)**: чтобы сохранить размер выходной карты, вход дополняется нулями по краям. Например, для ядра \(3 \times 3\) добавляется по одному пикселю с каждой стороны.
- **Шаг свертки (stride)**: определяет, на сколько пикселей смещается ядро при каждом шаге. Шаг \(s=1\) означает последовательное перемещение; шаг \(s>1\) уменьшает размер выходной карты и повышает вычислительную эффективность, но снижает разрешение.

Таким образом, сверточные сети эффективно извлекают иерархические признаки из изображений, а управление дополнением и шагом позволяет контролировать размерность и детализацию выходных данных.

# Билет 7

<img width="1100" height="433" alt="image" src="https://github.com/user-attachments/assets/8187765f-d55b-45be-b34e-1a488b64867e" />

**Ответ на вопрос 1**

**Однослойные искусственные нейронные сети. Обучение. Методы обучения.**

**Однослойные искусственные нейронные сети** представляют собой простейшую сетевую архитектуру, состоящую из входного слоя (точки распределения сигналов) и одного выходного (вычислительного) слоя нейронов. Каждый вход соединен с каждым нейроном отдельным синаптическим весом, образующим матрицу весов **W**. Выходной вектор **N** вычисляется как матричное умножение входного вектора **X** на матрицу весов: **N = XW**. Основная задача такой сети — классификация образов.

**Обучение** нейронной сети — это процесс настройки её свободных параметров (весов и порогов) посредством моделирования внешней среды, в которую сеть встроена. Процесс включает три этапа:
1.  Поступление стимулов из внешней среды.
2.  Изменение свободных параметров сети.
3.  Изменение реакции сети на последующие возбуждения.

**Методы обучения** классифицируются в зависимости от способа связи сети с внешним миром и корректировки весов:

1.  **Обучение с учителем (Supervised Learning):** Для каждого входного вектора **X** из обучающего множества существует требуемый (целевой) выходной вектор. Алгоритм обучения последовательно изменяет веса сети, минимизируя разницу между фактическим и целевым выходом. Яркий пример — алгоритм обучения персептрона Розенблатта.

2.  **Обучение без учителя (Unsupervised Learning):** Обучающее множество состоит только из входных векторов. Алгоритм подстраивает веса сети таким образом, чтобы близкие входные векторы порождали схожие выходы. Сеть самоорганизуется, выявляя скрытые закономерности в данных.

3.  **Обучение с подкреплением (Reinforcement Learning):** Сеть (агент) взаимодействует со средой, получая от неё сигналы подкрепления (награду или штраф) в зависимости от выбранного действия. Цель — максимизировать суммарное подкрепление. Это промежуточный вариант между обучением с учителем и без.

**Классический алгоритм обучения однослойного персептрона** основан на **правиле Хебба** (и его модификациях). Правило Хебба гласит: сила синаптической связи между двумя нейронами увеличивается, если они активируются одновременно (положительная корреляция). В контексте обучения персептрона это правило преобразуется в процедуру коррекции весов:
*   Если выход нейрона правильный — веса не меняются.
*   Если выход ошибочный — веса корректируются пропорционально входному сигналу и разности между целевым и фактическим выходом. Этот процесс напоминает метод «поощрения–наказания».


**Ответ на вопрос 2**

**Рекуррентные сети. Сети Хопфилда. Структура сети Хопфилда.**

**Рекуррентные сети** — это класс нейронных сетей, в которых между нейронами существуют обратные связи, что позволяет сети сохранять информацию о предыдущих состояниях. Они применяются для обработки последовательных данных, где порядок элементов важен (распознавание речи, текста, временные ряды).

**Сеть Хопфилда** — это тип рекуррентной нейронной сети, предложенный Дж. Хопфилдом. Она является ассоциативной памятью: способна сохранять образы (векторы) и восстанавливать их по неполным или искаженным входным данным.

**Структура сети Хопфилда**:
1. **Архитектура**: сеть состоит из одного слоя нейронов, каждый из которых связан со всеми остальными, кроме самого себя. Связи симметричны: \( w_{ij} = w_{ji} \).
2. **Нейроны**: бинарные (состояние +1 или -1) или с непрерывной активацией.
3. **Обучение**: веса рассчитываются по правилу Хебба на основе обучающих образцов:
   \[
   w_{ij} = \sum_{s=1}^{p} x_i^{(s)} x_j^{(s)} \quad (i \neq j),
   \]
   где \( p \) — число образцов, \( x_i^{(s)} \) — значение \( i \)-го компонента \( s \)-го образа.
4. **Функционирование**: сеть работает итеративно. На каждом шаге случайно выбирается нейрон, и его состояние обновляется по правилу:
   \[
   S_i = \sum_{j \neq i} w_{ij} x_j, \quad x_i^{\text{нов}} = \text{sign}(S_i).
   \]
   Процесс продолжается до достижения стабильного состояния (аттрактора), которое соответствует одному из запомненных образов.

**Назначение**: сеть Хопфилда используется для ассоциативного recall, решения задач оптимизации (например, задачи коммивояжёра) и как модель автоассоциативной памяти.

**Ответ на вопрос 3**

**Методы обучения глубоких сетей. Алгоритм BFGS.**

Алгоритм Бройдена–Флетчера–Гольдфарба–Шанно (BFGS) – это квазиньютоновский метод оптимизации, который пытается использовать преимущества метода Ньютона без вычисления обратного гессиана. Он аппроксимирует обратный гессиан матрицей \( M_t \), которая итеративно уточняется с помощью обновлений низкого ранга. Направление спуска вычисляется как \( \rho_t = M_t g_t \), после чего выполняется линейный поиск для определения шага \( \varepsilon^* \). Обновление параметров: \( \theta_{t+1} = \theta_t + \varepsilon^* \rho_t \).  
Основной недостаток BFGS — необходимость хранения матрицы \( M \) размером \( O(n^2) \), что делает его непригодным для очень больших моделей. Для уменьшения потребления памяти используется ограниченная версия — L-BFGS, которая хранит лишь несколько векторов и требует памяти \( O(n) \).

# Билет 8

<img width="1102" height="473" alt="image" src="https://github.com/user-attachments/assets/07c61cbb-a57a-49e2-9edd-8c38a6662b09" />
**Ответ на вопрос 1**

**Правила обучения Хебба. Синаптическая связь между нейронами. Алгоритм обучения по правилу Хебба.**

**Синаптическая связь между нейронами** — это соединение, через которое передаётся сигнал от одного нейрона к другому. Согласно нейробиологическому наблюдению Дональда Хебба (1949 г.), эффективность такой связи (синаптический вес) изменяется в зависимости от активности взаимодействующих нейронов.

**Правило обучения Хебба** (постулат Хебба) можно сформулировать так:
*   Если два нейрона по обе стороны синапса активируются **одновременно** (синхронно), то сила синаптической связи между ними **возрастает**.
*   Если два нейрона активируются **асинхронно**, то связь **ослабляется**.

Это правило основано на четырёх ключевых механизмах: **зависимость от времени**, **локальность**, **интерактивность** (взаимодействие сигналов с двух сторон синапса) и **корреляция** между предсинаптической и постсинаптической активностью.

**Алгоритм обучения по правилу Хебба** для однослойного перцептрона с учителем можно представить следующими шагами:

1.  **Инициализация.** Задать начальные (часто случайные, небольшие) значения весов \( w_{ij} \) и порога \( T \). Установить коэффициент обучения \( \eta \) (обычно \( \eta = 1 \)).

2.  **Подача обучающего примера.** На вход сети подаётся входной вектор \( X = (x_1, x_2, ..., x_n) \) с соответствующим целевым (эталонным) выходом \( y_{целевое} \).

3.  **Вычисление выхода сети.** Рассчитывается взвешенная сумма входов (NET) и выход нейрона \( y_{выход} \) с помощью активационной функции (например, пороговой или знаковой).

4.  **Коррекция весов.** Если вычисленный выход \( y_{выход} \) не совпадает с целевым \( y_{целевое} \), производится модификация весов и порога по формулам правила Хебба:
<img width="488" height="127" alt="image" src="https://github.com/user-attachments/assets/1623485a-1176-420a-b679-92ac4f0dad2f" />

    Если выход правильный, веса не изменяются.

5.  **Проверка условия останова.** Алгоритм повторяет шаги 2-4 для всех векторов обучающей выборки. Цикл продолжается до тех пор, пока сеть не перестанет ошибаться на всём обучающем множестве (или пока не будет достигнуто заданное число итераций).

Таким образом, алгоритм Хебба — это локальный и интерактивный процесс, в котором подстройка каждого веса зависит только от активности связанных с ним входного и выходного нейронов.

**Ответ на вопрос 2**

**Рекуррентные сети. Сети Хопфилда. Алгоритм формирования матрицы синаптических весов.**

**Рекуррентные сети** – это нейронные сети, в которых существуют обратные связи, позволяющие передавать информацию от выходов нейронов обратно на входы (в том числе на входы самих себя). Это позволяет сети сохранять состояние (память) о предыдущих входных данных и использовать его при обработке последующих. Такие сети применяются для задач обработки последовательностей: распознавание речи, машинный перевод, анализ временных рядов.

**Сети Хопфилда** – частный случай рекуррентной сети, предложенный Джоном Хопфилдом. Это однослойная сеть с симметричными весами и обратными связями между всеми нейронами. Каждый нейрон связан со всеми остальными, кроме самого себя (или иногда с самим собой). Сеть функционирует как ассоциативная память: она способна восстановить запомненный образ по его искаженному или неполному варианту.

**Алгоритм формирования матрицы синаптических весов для сети Хопфилда** (правило Хебба для ортогональных образов):

1. Пусть заданы \( p \) бинарных образцов (векторов) \( \mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \dots, \mathbf{x}^{(p)} \), где каждый вектор имеет размерность \( n \) и его элементы принимают значения \( +1 \) или \( -1 \).

2. Матрица синаптических весов \( W \) размерности \( n \times n \) вычисляется по формуле:

<img width="510" height="133" alt="image" src="https://github.com/user-attachments/assets/4ae18801-71ab-4456-a962-23bf1a633cb7" />


где \( w_{ij} \) – вес связи от нейрона \( j \) к нейрону \( i \), \( x_i^{(k)} \) – \( i \)-й элемент \( k \)-го образца.

3. Матрица \( W \) является симметричной (\( w_{ij} = w_{ji} \)) и имеет нули на главной диагонали.

**Ответ на вопрос 3**

**Стратегии оптимизации и метаалгоритмы. Пакетная нормировка. Описание метода.**

Стратегии оптимизации в глубоком обучении часто являются не готовыми алгоритмами, а общими шаблонами, которые можно адаптировать для конкретных задач.  
**Пакетная нормировка** — это один из таких методов, представляющий собой **адаптивную перепараметризацию**, предназначенную для ускорения обучения и стабилизации работы глубоких сетей. Она решает проблему **внутреннего ковариантного сдвига** — изменения распределения входных данных для скрытых слоев при обновлении параметров.

**Описание метода:**  
Пусть на вход слоя подается пакет данных \( B = \{x_1, ..., x_m\} \). Для каждого измерения \( k \) вычисляются среднее значение и дисперсия по пакету:

<img width="539" height="106" alt="image" src="https://github.com/user-attachments/assets/f68781af-ca08-4605-87cc-ae2863b29085" />


Затем данные нормализуются:

<img width="215" height="96" alt="image" src="https://github.com/user-attachments/assets/1e4326c8-a7b9-4566-b5c4-61b14d3793ad" />

где \( \epsilon \) — малая константа для численной устойчивости.  
Чтобы сохранить выразительность сети, вводятся два обучаемых параметра — **масштаб** \( \gamma \) и **сдвиг** \( \beta \):

<img width="176" height="51" alt="image" src="https://github.com/user-attachments/assets/98d4b817-a8ed-44f8-8bd1-89cedc9c3583" />


Эти параметры обучаются вместе с остальными весами сети, что позволяет сохранить возможность нелинейных преобразований. Пакетная нормировка применяется к каждому слою, что ускоряет сходимость и позволяет использовать более высокие скорости обучения.

# Билет 9

<img width="1101" height="455" alt="image" src="https://github.com/user-attachments/assets/c208dbde-c099-4044-855e-50e6ee7c072e" />

**Ответ на вопрос 1**

**Алгоритм обучения по правилу Хебба. Линейно и нелинейно-разделимые классы. Персептрон Розенблатта.**

**Алгоритм обучения по правилу Хебба** — это итеративный метод настройки весов нейрона, основанный на принципе «синапсы, активируемые вместе, усиливаются». Для каждого обучающего примера (входной вектор **X** и целевой выход **d**) выполняются шаги:
1.  Вычисляется активация нейрона: \( NET = \sum w_i x_i - T \), где \( w_i \) — веса, \( T \) — порог.
2.  Выходной сигнал \( y \) определяется активационной функцией (например, знаковой: \( y = \text{sgn}(NET) \) или пороговой).
3.  Если выход \( y \) не совпадает с целевым значением \( d \), веса и порог корректируются:
<img width="398" height="155" alt="image" src="https://github.com/user-attachments/assets/9e6b65cb-2ea3-4e06-af19-7f76b0da29a6" />

    где \( \eta \) — коэффициент обучения (часто \( \eta = 1 \)). Если выход правильный, коррекция не производится.
4.  Шаги повторяются для всех примеров обучающей выборки, пока не будет достигнута сходимость (отсутствие ошибок).

**Линейно и нелинейно-разделимые классы:**
*   **Линейно-разделимые классы** могут быть разделены прямой линией (в двумерном пространстве) или гиперплоскостью (в многомерном). Пример: логические функции «И» и «ИЛИ». Однослойный перцептрон может решать только такие задачи.
*   **Нелинейно-разделимые классы** не могут быть разделены гиперплоскостью (например, функция «исключающее ИЛИ» — XOR). Для их классификации требуются многослойные сети (многослойный перцептрон) с нелинейными активационными функциями.

**Персептрон Розенблатта** — первая модель искусственной нейронной сети (1958 г.), состоящая из трёх типов элементов:
1.  **S-элементы (сенсоры):** Формируют входные сигналы.
2.  **A-элементы (ассоциативные):** Обрабатывают входные сигналы через взвешенные связи (S–A связи) и активируются, если взвешенная сумма превышает порог. Являются детекторами признаков.
3.  **R-элементы (реагирующие):** Формируют итоговый выход сети на основе сигналов от A-элементов.

Обучение персептрона по методу Розенблатта аналогично правилу Хебба с «поощрением-наказанием»: веса корректируются только при ошибке, что позволяет сети обучаться распознаванию образов (например, чётности цифр). Персептрон доказал способность обучаться всему, что может реализовать, но только для линейно-разделимых задач.

**Ответ на вопрос 2**

**Рекуррентные сети. Сеть Хемминга. Структура сети Хемминга.**

**Рекуррентные сети** — это нейронные сети, имеющие обратные связи, что позволяет им сохранять информацию о предыдущих состояниях и обрабатывать последовательности данных, где порядок элементов важен (например, речь, текст).

**Сеть Хемминга** — это трёхслойная рекуррентная структура, предложенная Р. Липпманом, которая является развитием сети Хопфилда. Она позиционируется как специализированное гетероассоциативное запоминающее устройство. Основная идея состоит в минимизации расстояния Хемминга между тестовым вектором, подаваемым на вход сети, и векторами обучающих выборок, закодированными в структуре сети.

**Структура сети Хемминга** включает:
1. **Первый слой**: однонаправленное распространение сигналов от входа к выходу с фиксированными весами.
2. **Второй слой (MAXNET)**: состоит из нейронов, связанных обратными связями по принципу «каждый с каждым». Нейроны этого слоя функционируют в режиме WTA (Winner Takes All — победитель получает все), где активируется только один нейрон с максимальной активацией. Веса между нейронами отрицательные (обычно \(-\epsilon\)), а связь нейрона с самим собой положительная (\(+1\)).
3. **Третий слой**: выходной однонаправленный слой, формирующий выходной вектор, в котором только один нейрон имеет выходное значение, равное 1, а остальные — 0.

Сеть используется для задач классификации образов, где необходимо найти наиболее близкий сохранённый образ к входному вектору на основе расстояния Хемминга.

**Ответ на вопрос 3**

**Алгоритмы с адаптивной скоростью обучения. Алгоритм AdaGrad.**

Алгоритм **AdaGrad** адаптирует скорость обучения для каждого параметра модели индивидуально. Для этого он накапливает сумму квадратов всех прошлых значений градиента по каждому параметру и умножает глобальную скорость обучения на коэффициент, обратно пропорциональный квадратному корню из этой суммы.

Основная формула обновления параметра имеет вид:

<img width="303" height="94" alt="image" src="https://github.com/user-attachments/assets/00b85069-0e1d-41a6-8f0b-7914f84d77f7" />


где:
- \( \epsilon \) — глобальная скорость обучения,
- \( \delta \) — малая константа для устойчивости деления,
- \( G_t \) — сумма квадратов градиентов до шага \( t \),
- \( g_t \) — текущий градиент,
- \( \odot \) — поэлементное умножение.

**Преимущество** AdaGrad в том, что он автоматически уменьшает скорость обучения для параметров с большими градиентами, что особенно полезно в задачах с разреженными данными.

**Недостаток** — накопление квадратов градиентов с самого начала обучения может привести к слишком сильному падению эффективной скорости обучения, что делает алгоритм менее подходящим для глубоких нейронных сетей в длительных процессах обучения.

# Билет 10

<img width="1098" height="422" alt="image" src="https://github.com/user-attachments/assets/e66ac2dd-2ad4-47db-9d2d-ec5c71d800a6" />

**Ответ на вопрос 1**

**Персептрон Розенблатта. Алгоритм обучения персептрона Розенблатта. Распознавание букв.**

**Персептрон Розенблатта** – это первая искусственная нейронная сеть, созданная Ф. Розенблаттом в 1958–1961 гг., имитирующая процесс восприятия информации мозгом. Он состоял из трёх типов элементов: сенсорных (S), ассоциативных (A) и реагирующих (R). Персептрон был предназначен для решения задачи классификации и распознавания образов, в частности букв латинского (а позже и русского) алфавита.

**Алгоритм обучения персептрона Розенблатта (дельта-правило)** – это метод обучения с учителем, основанный на градиентном спуске для минимизации ошибки. Алгоритм включает следующие шаги:
1. **Инициализация весовых коэффициентов и порогов** значениями, близкими к нулю.
2. **Подача на вход** очередного входного вектора \( X \) из обучающей выборки.
3. **Вычисление взвешенной суммы** для каждого нейрона: 
<img width="224" height="110" alt="image" src="https://github.com/user-attachments/assets/3d7a2ebf-94be-4293-bcb6-aad34c99c888" />

4. **Вычисление выхода нейрона** с помощью пороговой функции:
<img width="508" height="117" alt="image" src="https://github.com/user-attachments/assets/ab8b439e-362d-4ec7-94f6-6d49fe2d768f" />

5. **Вычисление ошибки** для каждого нейрона: \( e_j = d_j - y_j \), где \( d_j \) – целевое значение.
6. **Коррекция весов** по формуле:
<img width="402" height="68" alt="image" src="https://github.com/user-attachments/assets/2578d505-89f3-40d0-96cd-2dad50b47e20" />

   где \( \eta \) – скорость обучения (\( 0 < \eta < 1 \)).
7. **Повторение шагов 2–6** до тех пор, пока ошибка не станет меньше заданного порога.

**Распознавание букв**: Персептрон Розенблатта успешно применялся для распознавания букв алфавита. Например, для распознавания русских букв использовалась сеть с 33 выходными нейронами (по одному на каждую букву). При предъявлении буквы «А» активировался первый выходной нейрон (выход = 1), остальные выдавали 0. Обучение проводилось на наборах карточек с буквами. После обучения персептрон демонстрировал свойство **обобщения** – мог распознавать буквы, напечатанные с искажениями или другим шрифтом. Это подтвердило возможность моделирования интеллектуальных задач с помощью нейронных сетей.

**Ответ на вопрос 2**

**Сети встречного распространения. Обучение слоя Кохонена. Предварительная обработка входных векторов. Выбор начальных значений весовых векторов.**

**Сети встречного распространения** представляют собой гибридную архитектуру, объединяющую самоорганизующуюся карту **Кохонена** (слой 1) и звезду **Гроссберга** (слой 2). Сеть обучается ассоциировать входные векторы с выходными и обладает способностью к обобщению.

**Обучение слоя Кохонена** проводится **без учителя**. Для каждого входного вектора вычисляются скалярные произведения с весовыми векторами всех нейронов этого слоя. Нейрон с **максимальным значением** объявляется победителем. Его веса корректируются по формуле:
<img width="481" height="71" alt="image" src="https://github.com/user-attachments/assets/c45a88a8-6f66-4d86-a16d-97ae14969bf8" />

где \(\alpha\) – коэффициент скорости обучения (\(0 < \alpha < 1\)). Процесс приближает веса победившего нейрона к входному вектору.

**Предварительная обработка входных векторов** заключается в их **нормировке** – приведении к единичной длине. Это необходимо, так как в основе обучения слоя Кохонена лежит сравнение направлений векторов (через скалярное произведение), а не их абсолютных величин. Нормированный вектор имеет длину, равную 1, в \(n\)-мерном пространстве.

**Выбор начальных значений весовых векторов** является важным этапом. Для эффективного разделения классов веса должны быть распределены в соответствии с плотностью входных данных. На практике часто используется метод **выпуклой комбинации (convex combination method)**. Начальные веса устанавливаются равными \(1/\sqrt{n}\) (где \(n\) – количество входов), что делает их единичными. Входные компоненты преобразуются по формуле:
<img width="251" height="89" alt="image" src="https://github.com/user-attachments/assets/a3d35c71-20a9-4962-9e6e-b4b8b19e6620" />

В начале обучения параметр \(a\) выбирается малым, что делает входные векторы близкими к весовым. В процессе обучения \(a\) постепенно увеличивается до 1, позволяя сети четко разделить классы входных векторов и закрепить их за определенными нейронами Кохонена.

**Ответ на вопрос 3**

**Алгоритмы с адаптивной скоростью обучения. Алгоритм RMSProp.**

Алгоритм **RMSProp** (Root Mean Square Propagation) является улучшением AdaGrad, предназначенным для решения проблемы преждевременного и чрезмерного снижения скорости обучения. Вместо накопления всех квадратов градиентов, RMSProp использует экспоненциально взвешенное скользящее среднее квадратов градиентов.

Основные шаги алгоритма на каждой итерации:

1. Вычисление градиента \( g_t \).
2. Обновление скользящего среднего квадратов градиентов:
<img width="430" height="61" alt="image" src="https://github.com/user-attachments/assets/8127eb17-77eb-4738-aa74-68d6f2acaa86" />

   где \( \rho \) — коэффициент затухания (обычно 0.9).
3. Вычисление обновления параметров:
<img width="293" height="84" alt="image" src="https://github.com/user-attachments/assets/6c676d0b-ebd7-41f8-bb46-7130c75314e2" />

   где \( \epsilon \) — глобальная скорость обучения, \( \delta \) — малая константа для устойчивости.

**Преимущества RMSProp:**
- Быстрая адаптация скорости обучения для каждого параметра.
- Эффективен на нестационарных задачах и при обучении глубоких сетей.
- Хорошо справляется с затуханием скорости обучения, характерным для AdaGrad.

**Эмпирически RMSProp** считается одним из наиболее эффективных и практичных алгоритмов для оптимизации глубоких нейронных сетей.

# Билет 11

<img width="1096" height="445" alt="image" src="https://github.com/user-attachments/assets/a4e09a52-11cf-466a-ac36-7ab4145dca84" />

**Ответ на вопрос 1**

**Персептрон Розенблатта. Обобщенное дельта-правило. Графическое изображение функции ошибки персептрона.**

**Персептрон Розенблатта** – первая искусственная нейронная сеть (Ф. Розенблатт, 1958‑1961 гг.), моделирующая процесс восприятия. Состоит из сенсорных (S), ассоциативных (A) и реагирующих (R) элементов. Используется для задач классификации, например распознавания букв.

**Обобщенное дельта-правило** – развитие классического правила для персептронов с **непрерывными активационными функциями** (например, сигмоидой). Цель – минимизация **квадратичной ошибки**:

<img width="270" height="112" alt="image" src="https://github.com/user-attachments/assets/571e3aae-b9fa-4c6a-a6a7-907c2b50671f" />


где \(d_i\) – желаемый выход, \(y_i\) – реальный выход.

Коррекция весов производится по формуле:

<img width="223" height="50" alt="image" src="https://github.com/user-attachments/assets/3299b2a0-effe-40e1-9203-93d580263cf8" />


где \(\eta\) – скорость обучения, \(x_j\) – входной сигнал, а **нейронная ошибка** \(\delta_i\) вычисляется как:

<img width="310" height="61" alt="image" src="https://github.com/user-attachments/assets/780bc295-41d7-4bf1-bdfc-944b41b97bf5" />


(для сигмоидальной функции активации). Это правило обеспечивает более быструю сходимость и точную обработку по сравнению с простым дельта-правилом.

**Графическое изображение функции ошибки персептрона**. Ошибка \(\varepsilon\) зависит от всех весов \(w_{ij}\), т.е. \(\varepsilon = \varepsilon(w_{ij})\). В многомерном пространстве параметров эта функция образует **гиперповерхность**. Для наглядности, если «заморозить» все веса кроме двух (\(w_{ij}\) и \(w_{ij+1}\)), то в трёхмерных координатах \((w_{ij}, w_{ij+1}, \varepsilon)\) эта гиперповерхность имеет вид **псевдопараболоида** (похожего на параболоид). **Процесс обучения** (коррекция весов) соответствует поиску самой нижней точки этой поверхности – минимума функции ошибки. Таким образом, задача обучения персептрона сводится к **оптимизационной задаче минимизации** \(\varepsilon(w_{ij})\) в многомерном пространстве весов.

**Ответ на вопрос 2**

**Сети на основе радиальных базисных функций. Обучение радиальной сети. Сравнение сетей RBF и многослойных персептронов.**

**Сети на основе радиальных базисных функций (RBF-сети)** – это трёхслойные нейронные сети прямого распространения, предназначенные для аппроксимации функций и решения задач классификации. Архитектура включает:
- Входной слой (сенсорные элементы).
- **Единственный скрытый слой** с нейронами, использующими **радиальные базисные функции** (например, гауссову функцию). Каждый нейрон вычисляет выход как:
<img width="613" height="103" alt="image" src="https://github.com/user-attachments/assets/266b4e89-c66d-4a7f-8a98-f5aeb2e54128" />

  где \( C_i \) – центр функции, \( \sigma_i \) – параметр ширины.
- Выходной слой состоит из **линейных нейронов**, суммирующих взвешенные выходы скрытого слоя.

**Теорема Ковера** утверждает, что нелинейное преобразование входных данных в пространство более высокой размерности (скрытый слой) повышает вероятность линейной разделимости классов, что позволяет решать сложные задачи классификации с помощью всего двух слоёв.

**Обучение радиальной сети** проводится в два этапа:
1. **Подбор центров \( C_i \) и параметров \( \sigma_i \)** скрытого слоя (обучение без учителя). Обычно используется алгоритм **K-средних (k-means)** для кластеризации обучающих данных и размещения центров в кластерах. Параметры \( \sigma_i \) определяются на основе расстояний до ближайших соседних центров.
2. **Подбор весов выходного слоя** (обучение с учителем). После фиксации параметров скрытого слоя веса выходного слоя рассчитываются методом **наименьших квадратов** или через **псевдообратную матрицу**:
<img width="279" height="50" alt="image" src="https://github.com/user-attachments/assets/4c6ac469-b2e2-4cb0-bb48-42e837ebc2fc" />

   где \( F \) – матрица выходов скрытого слоя для всех обучающих примеров, \( Y \) – целевые выходы.

**Сравнение сетей RBF и многослойных персептронов (MLP):**
1. **Количество скрытых слоёв:** RBF – один скрытый слой; MLP – может иметь несколько скрытых слоёв.
2. **Нейроны скрытого слоя:** В RBF – радиальные базисные функции (например, гауссовы); в MLP – обычно однотипные нейроны (сигмоидные, ReLU и т.д.).
3. **Нелинейность:** В RBF скрытый слой – нелинейный, выходной – линейный; в MLP (как классификаторе) оба слоя нелинейны.
4. **Аргумент активации:** В RBF – **евклидово расстояние** между входом и центром; в MLP – **скалярное произведение** входа и весов.
5. **Аппроксимация:** RBF обеспечивает **локальную аппроксимацию** (функции сосредоточены вокруг центров); MLP – **глобальную аппроксимацию** (все веса влияют на выход).
6. **Число параметров:** Для одинаковой точности MLP часто требует меньше параметров, чем RBF.
7. **Интерпретируемость:** Центры RBF могут соответствовать кластерам данных, что делает сеть более интерпретируемой.
8. **Обучение:** Обучение RBF разделено на две фазы (без учителя + с учителем), что может быть проще, но требует подбора центров; MLP обучается единым алгоритмом обратного распространения ошибки.

Таким образом, RBF-сети эффективны для задач, где данные естественно кластеризуются, и требуется локальная аппроксимация, в то время как MLP более универсальны и могут строить более сложные иерархические представления за счёт глубины.

**Ответ на вопрос 3**

**Сверточные сети. Биологическая мотивация. Примеры тензоров. Четырехмерный тензор.**

**Сверточные нейронные сети (СНС)** — это специальный класс нейронных сетей, предназначенных для эффективной обработки данных с сеточной структурой, таких как изображения. Их архитектура вдохновлена организацией зрительной коры головного мозга.

**Биологическая мотивация**  
Зрительная кора состоит из иерархически организованных зон (V1, V2, V3, V4, V5, V6, V7), каждая из которых отвечает за извлечение определённых признаков из изображения:
- **V1** — выделяет локальные признаки (границы, ориентацию, пространственную частоту).
- **V2** — обобщает локальные признаки, добавляет бинокулярное зрение.
- **V3** — распознаёт цвет и текстуры.
- **V4** — определяет геометрические фигуры и очертания.
- **V5** — анализирует движение.
- **V6, V7** — обобщают информацию, распознают сложные объекты (например, лица).

Эта иерархическая обработка, где низкие уровни извлекают простые признаки, а высокие — сложные и абстрактные, легла в основу архитектуры сверточных сетей.

**Тензоры в глубоком обучении**  
Тензор — это многомерный массив чисел, обобщающий понятия скаляра, вектора и матрицы. Примеры тензоров:
- **Скаляр** — тензор нулевого ранга (одно число).
- **Вектор** — тензор первого ранга (одномерный массив).
- **Матрица** — тензор второго ранга (двумерный массив).
- **Трёхмерный тензор** — массив матриц (например, набор изображений в оттенках серого).
- **Четырёхмерный тензор** — массив трёхмерных тензоров.

**Четырёхмерный тензор**  
В контексте обработки изображений четырёхмерный тензор используется для представления **пакета (batch) изображений**. Его форма зависит от принятого соглашения:
- **«Канал следует последним»** (TensorFlow): `(образцы, высота, ширина, каналы)`.
- **«Канал следует первым»** (Theano): `(образцы, каналы, высота, ширина)`.

Пример: пакет из 128 цветных изображений размером 256×256 пикселей представляется тензором формы `(128, 256, 256, 3)` в TensorFlow или `(128, 3, 256, 256)` в Theano. Для чёрно-белых изображений количество каналов равно 1.

Таким образом, сверточные сети, биологически мотивированные устройством зрительной системы, эффективно обрабатывают многомерные данные (тензоры), извлекая иерархические признаки из изображений.

# Билет 12

<img width="1110" height="453" alt="image" src="https://github.com/user-attachments/assets/78b3b2a7-7245-4664-a5a8-a85ac32f5f8e" />

**Ответ на вопрос 1**

**Функция «исключающего ИЛИ». Ограниченность однослойного персептрона. Геометрическая интерпретация к объяснению проблемы «Исключающего ИЛИ».**

Функция «исключающего ИЛИ» (XOR) — это логическая функция двух аргументов, которая принимает значение «истинно», когда только один из аргументов истинен. Её таблица истинности:

x₁ x₂ y
0 0 0
0 1 1
1 0 1
1 1 0

Однослойный персептрон с двумя входами принципиально не способен воспроизвести эту функцию. Это было строго доказано М. Минским и С. Пайпертом.

**Геометрическая интерпретация:** Работа однослойного персептрона сводится к разделению плоскости входных переменных (x₁, x₂) **пороговой прямой** (уравнение w₁x₁ + w₂x₂ = θ). Точки по одну сторону прямой соответствуют выходу «1», по другую — «0».

Для функции XOR точки (0,0) и (1,1) должны иметь выход «0», а точки (0,1) и (1,0) — выход «1». Невозможно провести одну прямую линию так, чтобы разделить эти две группы точек: точки с одинаковым выходом расположены **диагонально** относительно друг друга. Это делает задачу XOR **линейно неразделимой**.

Таким образом, ограниченность однослойного персептрона заключается в его способности решать **только линейно разделимые задачи**. Проблема XOR наглядно демонстрирует это фундаментальное ограничение, для преодоления которого потребовалось введение **многослойных сетей** со скрытыми слоями.

**Ответ на вопрос 2**

**Сети встречного распространения. Нормальное функционирование. Слой Кохонена. Слой Гроссберга.**

**Сеть встречного распространения** – это двухслойная гибридная сеть, в которой объединены **слой Кохонена** (самоорганизующийся) и **слой Гроссберга** (обучаемый с учителем). В **нормальном режиме функционирования** (режиме распознавания) на вход сети подается вектор **X**, и сеть выдает соответствующий выходной вектор **Y**.

Процесс происходит в два этапа:

1.  **Слой Кохонена (слой 1):**
    *   Каждый нейрон этого слоя вычисляет взвешенную сумму входов (скалярное произведение входного вектора **X** и своего весового вектора).
    *   Затем применяется правило **«победитель получает всё»**: только один нейрон, чей весовой вектор **наиболее близок** (имеет наибольшее скалярное произведение) к входному вектору, активируется, выдавая на выходе сигнал, равный 1.
    *   Все остальные нейроны слоя Кохонена выдают на выходе 0.
    *   Таким образом, слой Кохонена выполняет роль **детектора признаков** или кластеризатора, преобразуя входной вектор в позицию активированного нейрона-победителя.

2.  **Слой Гроссберга (слой 2):**
    *   Активированный нейрон-победитель из слоя Кохонена передает свой выходной сигнал (равный 1) на слой Гроссберга.
    *   Слой Гроссберга состоит из линейных нейронов, которые формируют итоговый выходной вектор **Y** как взвешенную сумму сигналов от слоя Кохонена.
    *   Поскольку активен только один нейрон Кохонена, выходной вектор **Y** фактически равен **вектору весов**, связывающих этот нейрон-победитель со всеми нейронами слоя Гроссберга.
    *   Таким образом, слой Гроссберга выполняет функцию **ассоциативной памяти**, преобразуя позицию победителя в конкретный требуемый выходной вектор.

**Итог:** В нормальном режиме сеть встречного распространения работает как **ассоциативная память с обобщением**. Входной вектор активирует определенный нейрон Кохонена, который через обученные веса слоя Гроссберга выдает соответствующий выходной образ. Это позволяет сети давать правильный выход даже для неполных или зашумленных входных данных.

**Ответ на вопрос 3**

**Алгоритмы с адаптивной скоростью обучения. Алгоритм Adam.**

Алгоритм **Adam** (Adaptive Moment Estimation) сочетает в себе идеи **RMSProp** и **метода импульса**. Он адаптивно настраивает скорость обучения для каждого параметра, используя оценки первого момента (среднее градиентов) и второго момента (нецентрированной дисперсии градиентов) с экспоненциальным затуханием.

Ключевые шаги алгоритма на каждой итерации \( t \):

1. **Обновление смещённых оценок моментов:**
   - Первый момент (аналог импульса):
<img width="361" height="55" alt="image" src="https://github.com/user-attachments/assets/117467e8-4733-494e-af1d-e8a644e2b4ba" />

   - Второй момент (аналог RMSProp):
<img width="410" height="65" alt="image" src="https://github.com/user-attachments/assets/06049103-e238-47d9-bbfc-533ff835dbeb" />

   где \( \beta_1, \beta_2 \in [0, 1) \) — коэффициенты затухания (по умолчанию 0.9 и 0.999).

2. **Коррекция смещения** (bias correction) для начальных шагов:
<img width="372" height="94" alt="image" src="https://github.com/user-attachments/assets/dd5179b4-cb13-4719-abae-5b42e5796d63" />


3. **Обновление параметров:**
<img width="301" height="75" alt="image" src="https://github.com/user-attachments/assets/f12d07e5-afa3-470c-b989-9a009a23e5dc" />

   где \( \epsilon \) — скорость обучения, \( \delta \) — малая константа для устойчивости (например, \( 10^{-8} \)).

**Преимущества Adam:**
- Автоматическая адаптация скорости обучения.
- Устойчивость к выбору гиперпараметров.
- Эффективность как для разреженных градиентов, так и для нестационарных задач.
- Широко используется в практике глубокого обучения благодаря своей надежности и скорости сходимости.

# Билет 13

<img width="1094" height="439" alt="image" src="https://github.com/user-attachments/assets/a20ee19b-34f5-435a-8aba-4ada429c6b48" />

**Ответ на вопрос 1**

**Линейная разделимость. Преодоление ограничения линейной разделимости. Эффективность запоминания.**

**Линейная разделимость** – это свойство множества точек (образов) в пространстве признаков, при котором существует хотя бы одна гиперплоскость, разделяющая точки разных классов. Для двух классов это означает, что все точки одного класса лежат по одну сторону гиперплоскости, а точки другого класса – по другую. Линейно разделимая задача может быть решена **однослойным перцептроном** (например, с использованием правила Хебба или дельта-правила). Пример – логические функции «И» и «ИЛИ».

**Ограничение линейной разделимости**: многие реальные задачи (например, функция «исключающее ИЛИ» – XOR) являются **нелинейно разделимыми**, т.е. не могут быть точно решены однослойным перцептроном. Это ограничение было показано Минским и Пейпертом в 1969 году и на время замедлило развитие нейросетевых исследований.

**Преодоление ограничения линейной разделимости** достигается следующими подходами:
1. **Многослойные нейронные сети** (многослойный перцептрон). Добавление одного или нескольких скрытых слоев позволяет сети строить сложные нелинейные разделяющие поверхности. Например, функция XOR легко решается двухслойной сетью.
2. **Использование нелинейных активационных функций** в скрытых слоях (сигмоида, гиперболический тангенс, ReLU). Это позволяет сети аппроксимировать любую непрерывную функцию (теорема о универсальной аппроксимации).
3. **Метод ядер (kernel trick)** и переход в пространство более высокой размерности. Например, в **RBF-сетях** входные данные нелинейно преобразуются в пространство более высокой размерности (скрытый слой с радиальными базисными функциями), где они становятся линейно разделимыми (теорема Ковера).
4. **Предобработка данных** (feature engineering) – создание новых признаков, которые делают задачу линейно разделимой в преобразованном пространстве.

**Эффективность запоминания** – способность нейронной сети сохранять и точно воспроизводить обученные образы. Однако важно различать:
- **Запоминание (переобучение)** – сеть точно запоминает обучающую выборку, но плохо обобщает на новые данные (низкая обобщающая способность).
- **Обобщение** – способность сети корректно классифицировать новые, ранее не виденные образы, что является основной целью обучения.

**Эффективность запоминания повышается**:
- С увеличением числа нейронов и синаптических весов.
- При использовании избыточной архитектуры (например, RBF-сеть с большим числом центров).
- При точной настройке весов (например, с помощью алгоритма обратного распространения).

Однако чрезмерное запоминание ведёт к **переобучению**. Для обеспечения обобщающей способности применяются методы регуляризации, отсев (dropout), а также использование проверочной и тестовой выборок.

Таким образом, преодоление ограничения линейной разделимости через многослойные и нелинейные модели позволило нейронным сетям решать сложные практические задачи, а баланс между запоминанием и обобщением является ключевым при проектировании эффективных нейросетевых архитектур.

**Ответ на вопрос 2**

**Стратегии обучения на основе RBF. Случайный выбор фиксированных центров.**

**Стратегии обучения RBF-сети** делятся на два основных этапа:

1.  **Определение параметров скрытого (радиально-базисного) слоя**: центров \( C_i \) и ширины (параметра разброса) \( \sigma_i \) для каждой радиальной функции (обычно гауссовой).
2.  **Расчет весов выходного (линейного) слоя**: после фиксации параметров скрытого слоя веса находятся аналитически, например, методом наименьших квадратов.

**Случайный выбор фиксированных центров (Random Selection of Fixed Centers)** — это простейшая и одна из самых быстрых стратегий обучения первого этапа.

**Алгоритм и суть метода:**
1.  **Случайная инициализация центров**: Центры \( C_i \) радиальных базисных функций выбираются **случайным образом** из множества входных обучающих векторов \( X \). Количество центров \( m \) задается заранее (и обычно много меньше числа обучающих примеров \( n \): \( m << n \)).
2.  **Фиксация центров**: После выбора центры **не изменяются** в процессе дальнейшего обучения. Они остаются постоянными.
3.  **Определение параметра ширины \( \sigma \)**:
    *   Часто используется **единое значение \( \sigma \)** для всех функций, которое выбирается эмпирически.
    *   Распространенная эвристика: \( \sigma \) устанавливается равным **среднему расстоянию между выбранными центрами** или некоторой его доле (например, <img width="117" height="47" alt="image" src="https://github.com/user-attachments/assets/d37ed072-a908-489c-9fb1-db6ccd05cad7" />
, где \( d_{max} \) — максимальное расстояние между выбранными центрами).
    *   Это обеспечивает определенную степень перекрытия областей активности соседних RBF-нейронов.
4.  **Расчет весов выходного слоя**: После фиксации центров и параметра \( \sigma \) рассчитывается матрица выходов скрытого слоя \( F \) для всех обучающих примеров. Затем веса выходного слоя \( W \) находятся как решение линейной системы (например, с помощью псевдообратной матрицы):
  <img width="264" height="74" alt="image" src="https://github.com/user-attachments/assets/71a25174-e813-4a6c-8992-2b272a325ec2" />

    где \( Y \) — матрица целевых выходов.

**Преимущества:**
*   **Высокая скорость обучения**, так как отсутствуют итеративные процедуры настройки центров.
*   **Простота реализации**.

**Недостатки:**
*   **Низкая точность (эффективность) аппроксимации**. Случайно выбранные центры могут плохо отражать структуру данных: они могут оказаться в малозначимых областях входного пространства, а важные области могут остаться без центров.
*   **Требует большого количества RBF-нейронов (центров)** для достижения приемлемой точности, что увеличивает размер модели.
*   **Чувствительность к шуму** в данных, так как центры выбираются непосредственно из обучающей выборки.

**Вывод:** Стратегия **случайного выбора фиксированных центров** является базовой и применяется, когда важна скорость обучения, а не максимальная точность, или как начальный этап для более сложных алгоритмов (например, K-средних). Для решения серьезных практических задач обычно используются более совершенные стратегии, такие как **обучение с помощью алгоритма K-средних** или **супервизорное обучение центров** с помощью градиентного спуска, которые позволяют размещать центры в наиболее информативных областях входного пространства.

**Ответ на вопрос 3**

**Методы обучения глубоких сетей. Метод Ньютона.**

Метод Ньютона — это метод оптимизации второго порядка, который использует информацию о кривизне функции потерь (матрицу Гессе) для более быстрой сходимости к минимуму. В отличие от градиентного спуска, метод Ньютона учитывает не только направление, но и кривизну поверхности ошибки.

**Основная формула обновления параметров:**
<img width="383" height="71" alt="image" src="https://github.com/user-attachments/assets/2f0414c8-e187-41ea-a809-2b7b683ede32" />

где:
- \( H(\theta_t) \) — матрица Гессе (вторых производных) функции потерь \( J \) по параметрам \( \theta \) в точке \( \theta_t \),
- \( \nabla J(\theta_t) \) — градиент функции потерь.

**Преимущества метода Ньютона:**
- Квадратичная скорость сходимости вблизи минимума.
- Более точное направление обновления за счёт учёта кривизны.

**Недостатки и ограничения в глубоком обучении:**
1. **Вычислительная сложность:** вычисление и обращение матрицы Гессе требует \( O(n^3) \) операций, где \( n \) — число параметров (может быть миллионы).
2. **Память:** хранение матрицы Гессе размером \( n \times n \) практически невозможно для больших сетей.
3. **Невыпуклость:** в глубоких сетях функция потерь невыпукла, матрица Гессе может быть неположительно определённой (особенно в седловых точках), что приводит к неверным направлениям обновления.
4. **Регуляризация:** для устойчивости часто добавляют константу к диагонали Гессе:
<img width="448" height="57" alt="image" src="https://github.com/user-attachments/assets/b66684aa-4112-4f7e-98d2-9a36f1bdce79" />

   где \( \alpha > 0 \) — параметр регуляризации.

Из-за этих ограничений метод Ньютона **редко используется напрямую** в обучении глубоких сетей, но его идеи лежат в основе квазиньютоновских методов (BFGS, L-BFGS) и методов второго порядка, адаптированных для больших моделей.

# Билет 14

<img width="1095" height="433" alt="image" src="https://github.com/user-attachments/assets/14159a62-7411-404a-acef-19b50fd140d1" />

**Ответ на вопрос 1**

**Функция «исключающего ИЛИ». Пример решения задачи «исключающее ИЛИ». Многослойные искусственные нейронные сети.**

**Функция «исключающее ИЛИ» (XOR)** — логическая операция, результат которой равен 1, если ровно один из входных аргументов равен 1, и 0 в противном случае.

Таблица истинности для XOR (с биполярными значениями 1 и -1):

| X₁ | X₂ | Y (XOR) |
|----|----|---------|
| -1 | -1 | -1      |
| -1 | 1  | 1       |
| 1  | -1 | 1       |
| 1  | 1  | -1      |

**Важность XOR**: эта функция является классическим примером **нелинейно разделимой** задачи. Однослойный перцептрон (линейный классификатор) не может построить гиперплоскость, которая разделила бы точки (1, -1) и (-1, 1) от точек (-1, -1) и (1, 1). Это ограничение было критически отмечено Минским и Пейпертом в 1969 году.

**Пример решения задачи XOR** с помощью **многослойной нейронной сети (многослойного перцептрона)**.

**Архитектура сети**:
*   **Входной слой**: 2 нейрона (X₁, X₂).
*   **Скрытый слой**: 2 нейрона (H₁, H₂) с нелинейной активационной функцией (например, сигмоидой или гиперболическим тангенсом).
*   **Выходной слой**: 1 нейрон (Y) с нелинейной или линейной активацией.

**Принцип решения**:
Скрытый слой преобразует входное пространство так, что задача становится линейно разделимой в новом (скрытом) пространстве. Выходной слой строит линейную разделяющую границу в этом преобразованном пространстве.

**Упрощенный алгоритм обучения** (например, с помощью обратного распространения ошибки):
1.  **Инициализация весов** случайными малыми значениями.
2.  **Прямой проход**: для каждой строки таблицы вычисляется выход сети.
    *   Сумма на скрытых нейронах:  

    *   Выход скрытых нейронов (через нелинейную функцию, например, сигмоиду):  
        \[ H_1 = f(S_{H1}), \quad H_2 = f(S_{H2}) \]
    *   Сумма на выходном нейроне:  
<img width="389" height="76" alt="image" src="https://github.com/user-attachments/assets/07f33fe2-4bf9-4ff2-8269-952cc63a04d9" />

    *   Выход сети:  
<img width="188" height="49" alt="image" src="https://github.com/user-attachments/assets/406192fe-fb60-4260-ab7a-2a980bb0cd9b" />

3.  **Вычисление ошибки**:  
<img width="301" height="79" alt="image" src="https://github.com/user-attachments/assets/7c2e4d5b-8b8b-4bc5-8963-ac6c41a017f2" />

4.  **Обратный проход (Backpropagation)**: вычисляются градиенты ошибки по всем весам (используется цепное правило) и веса корректируются в сторону уменьшения ошибки.

После успешного обучения сеть будет выдавать правильные значения для всех четырех комбинаций входов.

**Многослойные искусственные нейронные сети (ИНС)** — сети, содержащие один или несколько **скрытых слоев** между входным и выходным слоями.

**Ключевые особенности**:
*   **Способность решать нелинейно разделимые задачи** (благодаря наличию скрытых слоев и нелинейных активационных функций).
*   **Универсальная аппроксимация**: теоретически, многослойная сеть с одним скрытым слоем и достаточным количеством нейронов может аппроксимировать любую непрерывную функцию с любой заданной точностью.
*   **Иерархическое представление признаков**: на каждом последующем слое формируются более сложные и абстрактные признаки на основе комбинации признаков предыдущего слоя.

**Области применения**: распознавание образов, компьютерное зрение, обработка естественного языка, прогнозирование временных рядов и другие сложные задачи, где линейные модели недостаточны.

**Вывод**: Функция XOR является яркой демонстрацией ограниченности однослойных сетей и важности использования **многослойных архитектур** для решения реальных, нелинейных задач. Современные глубокие нейронные сети являются развитием этой идеи и содержат множество скрытых слоев для построения сложных иерархических моделей данных.

**Ответ на вопрос 2**

**Стратегии обучения на основе RBF. Выбор центров на основе самоорганизации.**

**Стратегии обучения RBF-сети** делятся на два ключевых этапа:
1.  **Определение параметров скрытого (радиально-базисного) слоя**: центров \( C_i \) и параметров ширины \( \sigma_i \).
2.  **Расчет весов выходного (линейного) слоя**, который является задачей линейной регрессии после фиксации параметров скрытого слоя.

**Выбор центров на основе самоорганизации (обучение без учителя)** — это наиболее распространённый и эффективный метод первого этапа, позволяющий автоматически размещать центры RBF-нейронов в областях входного пространства с высокой плотностью данных.

**Цель метода**: преобразовать входное пространство в пространство более высокой размерности (скрытое пространство), разместив центры базисных функций так, чтобы они наилучшим образом **представляли структуру обучающих данных**. Это повышает вероятность линейной разделимости классов в новом пространстве (в соответствии с теоремой Ковера).

**Основной алгоритм самоорганизации центров — K-средних (K-means):**
1.  **Инициализация**: случайным образом выбираются начальные положения \( K \) центров \( C_i(0) \) (где \( K \) равно числу нейронов скрытого слоя). Центры должны быть различны.
2.  **Кластеризация (ассоциация)**: для каждого обучающего вектора \( x(t) \) определяется **центр-победитель** \( C_w \), ближайший к нему по евклидову расстоянию:
<img width="378" height="74" alt="image" src="https://github.com/user-attachments/assets/c292c9b9-e577-4a27-9b59-731e8f2e3c26" />

3.  **Адаптация (обновление центров)**: Центр-победитель сдвигается в сторону текущего входного вектора:
<img width="553" height="88" alt="image" src="https://github.com/user-attachments/assets/39a54922-b76a-4d68-aa3d-b82f6e5dcc35" />

    где \( \eta(t) \) — коэффициент обучения, обычно уменьшающийся со временем (например, по правилу Даркена-Муди: \( \eta(t) = \frac{\eta_0}{1 + t/T} \)). Остальные центры не изменяются.
4.  **Итерация**: Шаги 2 и 3 повторяются до стабилизации положений центров (пока изменения не станут пренебрежимо малы).

**После определения центров** выполняется **расчет параметров ширины \( \sigma_i \)**. Распространённый способ — задать \( \sigma_i \) пропорционально среднему расстоянию от центра \( C_i \) до \( R \) его ближайших соседей (обычно \( R \) от 3 до 5):
<img width="313" height="110" alt="image" src="https://github.com/user-attachments/assets/ecf72521-d464-4ce8-b47d-8fa7c0d37c69" />

Это обеспечивает плавное перекрытие областей действия соседних RBF-функций и покрытие всего пространства данных.

**Преимущества подхода на основе самоорганизации:**
*   **Автоматическое определение** оптимальных положений центров на основе распределения данных.
*   **Повышение точности аппроксимации** по сравнению со случайным выбором центров.
*   **Эффективное использование нейронов**: центры концентрируются в информативных областях входного пространства.

**Недостатки:**
*   **Зависимость от начальной инициализации** (алгоритм может сходиться к локальным минимумам).
*   **Требует подбора количества центров \( K \)** (часто методом проб и ошибок или с использованием критериев кластеризации).
*   **Вычислительная сложность** выше, чем при случайном выборе.

**Вывод**: **Выбор центров на основе самоорганизации (K-means)** является основным, хорошо зарекомендовавшим себя методом обучения скрытого слоя RBF-сети. Он позволяет адаптивно настроить сеть на структуру конкретных данных, что обеспечивает высокую точность классификации и аппроксимации при решении практических задач. Данный метод отражает ключевую идею RBF-сетей: использование методов обучения **без учителя** для фазы предобработки данных и методов **с учителем** для финальной настройки.

**Ответ на вопрос 3**

**Оптимизация в обучении глубоких моделей. Импульсный метод.**

**Оптимизация в глубоком обучении** отличается от чистой оптимизации: целью является не минимизация функции стоимости \(J(\theta)\) на обучающем наборе, а улучшение обобщающей способности модели. Часто оптимизируют **суррогатную функцию потерь**, а алгоритмы останавливаются на основе **ранней остановки**, а не при достижении локального минимума. Важным аспектом является использование **мини-пакетов** для оценки градиента, что ускоряет вычисления и улучшает сходимость.

**Импульсный метод** – это техника ускорения обучения, особенно в условиях высокой кривизны, малых или зашумлённых градиентов. Он решает две основные проблемы: **плохую обусловленность матрицы Гессе** и **дисперсию стохастического градиента**.

**Принцип работы:**  
Вводится переменная \(v\) (скорость), которая представляет собой **экспоненциально затухающее скользящее среднее прошлых градиентов**. Обновление параметров происходит не только по текущему градиенту, но и с учётом накопленной скорости:
<img width="359" height="59" alt="image" src="https://github.com/user-attachments/assets/5dda4881-4a00-40c9-92ad-cad74c27fd2b" />

где \(\alpha\) – гиперпараметр импульса (обычно близок к 1, например 0.9), \(\epsilon\) – скорость обучения, \(g\) – текущая оценка градиента.

**Эффект:**  
Импульсный метод позволяет эффективно двигаться вдоль длинных узких "оврагов" функции стоимости, избегая осцилляций, характерных для обычного градиентного спуска. Он ускоряет сходимость в направлениях с устойчивым градиентом и стабилизирует обновления при зашумлённых градиентах.

# Билет 15

<img width="1096" height="435" alt="image" src="https://github.com/user-attachments/assets/91e37e32-dc77-49f8-9850-7bee456b5a95" />

**Ответ на вопрос 1**

**Метод обратного распространения ошибок. Обучение методом обратного распространения ошибок.**

**Метод обратного распространения ошибки (backpropagation)** – это основной алгоритм обучения многослойных нейронных сетей (персептронов). Его цель – эффективное вычисление градиента функции стоимости по всем весам сети для их последующего обновления.

**Принцип работы:**
1.  **Прямой проход (forward propagation):** Входной сигнал последовательно проходит через все слои сети, на каждом слое преобразуясь с помощью взвешенной суммы и активационной функции. На выходе сети получается прогноз, который сравнивается с целевым значением, вычисляя **функцию потерь (ошибку)**.
2.  **Обратный проход (backward propagation):** Вычисленная ошибка распространяется **обратно** от выходного слоя к входному. На этом этапе с помощью **цепного правила дифференцирования** рассчитываются частные производные функции ошибки по каждому весу сети (\(\frac{\partial E}{\partial w_{ij}}\)).
3.  **Обновление весов:** Полученные градиенты используются для корректировки весов сети в направлении, уменьшающем ошибку. Классическое правило обновления (стохастический градиентный спуск):
<img width="304" height="106" alt="image" src="https://github.com/user-attachments/assets/491da577-ce4c-41e8-86d7-13fbc8e95ccb" />

    где \(\eta\) – скорость обучения.

**Обучение методом обратного распространения** представляет собой итеративный процесс многократного повторения прямого и обратного проходов для всех примеров обучающей выборки (или их мини-пакетов). В результате веса сети настраиваются так, чтобы минимизировать среднюю ошибку на обучающих данных.

**Ответ на вопрос 2**

**Стратегии обучения на основе RBF. Выбор центров с учителем.**

**Радиально-базисные функции (RBF-сети)** – это тип нейронных сетей, обычно состоящих из трёх слоёв: входного, скрытого (RBF-слой) и выходного (линейный). Активация нейрона скрытого слоя определяется **радиально-базисной функцией** (чаще всего гауссовой), которая откликается на близость входного вектора к своему **центру**.

**Стратегии обучения RBF-сети** включают настройку трёх групп параметров:
1.  **Центры** \(c_j\) скрытых RBF-нейронов.
2.  **Ширины (разбросы)** \(\sigma_j\) этих функций.
3.  **Веса** \(w_{kj}\) выходного линейного слоя.

**Выбор центров с учителем** – это стратегия, при которой положение центров RBF-функций **настраивается** в процессе обучения вместе с остальными параметрами сети, используя обучающие данные и целевые значения (метки). Это делается с помощью градиентных методов (например, обратного распространения ошибки), где центры рассматриваются как обычные параметры, и градиент ошибки по ним вычисляется и используется для их обновления. Такой подход позволяет более гибко и точно адаптировать RBF-сеть к данным, но является более вычислительно сложным по сравнению с методами выбора центров без учителя (например, кластеризацией K-средних).

**Ответ на вопрос 3**

**Оптимизация в обучении глубоких моделей. Основные алгоритмы. Стохастический градиентный спуск.**

**Оптимизация в глубоком обучении** нацелена на минимизацию функции стоимости \(J(\theta)\), которая оценивает ошибку модели. В отличие от чистой оптимизации, здесь часто используется **суррогатная функция потерь**, а обучение останавливается по критерию **ранней остановки**, чтобы избежать переобучения.

**Основные алгоритмы** можно разделить на:
1.  **Пакетный градиентный спуск** – использует весь обучающий набор для вычисления градиента. Точен, но медленный и требовательный к памяти.
2.  **Стохастический градиентный спуск (СГС)** и его мини-пакетные варианты – наиболее распространённые на практике.
3.  **Алгоритмы с адаптивной скоростью обучения** (AdaGrad, RMSProp, Adam) – автоматически настраивают скорость обучения для каждого параметра.
4.  **Методы с учётом импульса** – ускоряют обучение в условиях плохой обусловленности или зашумлённых градиентов.
5.  **Приближённые методы второго порядка** (например, L-BFGS) – используют информацию о кривизне, но сложны для больших сетей.

**Стохастический градиентный спуск (СГС)** – это итеративный метод, где на каждом шаге градиент функции стоимости оценивается не по всему набору данных, а по **мини-пакету** (небольшой случайной подвыборке) примеров.

**Алгоритм СГС (основные шаги):**
1.  Инициализировать параметры \(\theta\) и выбрать скорость обучения \(\epsilon_k\) (которая обычно уменьшается со временем).
2.  Пока не выполнен критерий остановки:
    *   Выбрать случайный мини-пакет из \(m\) примеров.
    *   Вычислить оценку градиента:
<img width="423" height="107" alt="image" src="https://github.com/user-attachments/assets/4b5ea2c9-51fb-4cbb-87e4-fd24e01b1668" />

    *   Обновить параметры:
   <img width="182" height="63" alt="image" src="https://github.com/user-attachments/assets/ec8464e7-8620-4e73-91fa-8543a3c1e018" />


**Преимущества СГС:**
*   **Вычислительная эффективность:** время на одно обновление не зависит от размера всего набора данных.
*   **Быстрый прогресс на начальном этапе.**
*   **Сходимость возможна даже на очень больших наборах данных.**
*   **Шум, вносимый случайной выборкой, может помочь выйти из мелких локальных минимумов.**

**Недостатки/особенности:**
*   Оценка градиента зашумлена, что приводит к колебаниям траектории.
*   Требуется осторожный подбор и затухание скорости обучения \(\epsilon_k\).
*   Может медленно сходиться в "оврагах" функции стоимости или на плато. Для решения этих проблем часто используется **СГС с импульсом** или **алгоритмы с адаптивной скоростью обучения (Adam)**.

# Билет 16

<img width="1096" height="461" alt="image" src="https://github.com/user-attachments/assets/626e18be-5727-4543-88a0-30a9e05c4183" />

**Ответ на вопрос 1**

**Метод обратного распространения ошибок. Алгоритм обратного распространения ошибки**

**Метод обратного распространения ошибок** — это систематический алгоритм обучения многослойных нейронных сетей, основанный на распространении сигнала ошибки от выходов сети к её входам в направлении, обратном прямому распространению сигналов. Основная идея заключается в получении оценки ошибки для нейронов скрытых слоёв как взвешенной суммы ошибок последующего слоя, что позволяет корректировать весовые коэффициенты связей.

**Алгоритм обратного распространения ошибки** включает следующие шаги:

1. **Подача входного вектора** из обучающей пары на вход сети и вычисление выходного сигнала (прямое распространение).
2. **Вычисление ошибки** на выходе сети (например, квадратичной ошибки \(E = 0.5 \sum (d_j - y_j)^2\)).
3. **Расчёт ошибки для выходного слоя**:
<img width="194" height="33" alt="image" src="https://github.com/user-attachments/assets/324bf347-39d2-4873-a669-545e12d7be9d" />

4. **Расчёт ошибки для скрытых слоёв**:
<img width="216" height="48" alt="image" src="https://github.com/user-attachments/assets/d4f7a235-2f47-4df9-b721-8e4e26ba71b7" />

5. **Коррекция весов** с использованием дельта-правила:
   - Для связей между скрытым и выходным слоем:
<img width="182" height="34" alt="image" src="https://github.com/user-attachments/assets/a1761f95-0ed9-4be7-b167-7c89045d198c" />

   - Для связей между входным и скрытым слоем:
<img width="174" height="44" alt="image" src="https://github.com/user-attachments/assets/dd3ce690-6e2f-4006-b333-8b96bf13ea45" />

   где \(\alpha\) — коэффициент обучения.
6. **Повторение шагов** для всех обучающих примеров до достижения приемлемого уровня ошибки.

Таким образом, алгоритм сочетает прямое распространение сигнала для вычисления выхода и обратное распространение ошибки для корректировки весов, минимизируя ошибку сети.

**Ответ на вопрос 2**

**Нейронные сети Кохонена. Задачи кластеризации. Структура сети Кохонена. Одномерная сеть Кохонена.**

**Нейронные сети Кохонена** относятся к самоорганизующимся нейронным сетям и предназначены для решения **задачи кластеризации** — разделения множества объектов на группы «похожих» объектов (кластеров) без заранее известных меток классов. В отличие от классификации, кластеры формируются в процессе обучения.

Формально задача кластеризации: дано множество объектов \( I = \{i_1, i_2, ..., i_n\} \), каждый из которых описывается вектором признаков \( x_j \). Требуется построить множество кластеров \( C = \{c_1, c_2, ..., c_g\} \) и отображение \( F : I \to C \), так чтобы объекты внутри кластера были близки по выбранной метрике расстояния \( d(i_j, i_p) \).

**Структура сети Кохонена** включает:
- **Входной слой** (распределяет входные сигналы);
- **Активный слой** (один или несколько нейронов Кохонена).

Сеть является **однослойной**, так как входной слой лишь передает сигналы. Активный слой может быть **одномерным** (линейная структура) или **двумерным** (плоская решетка). В одномерном случае нейроны расположены в одну линию, что соответствует простейшей форме организации и часто используется для базовой кластеризации.

Различают два варианта:
1. **Слой Кохонена** — нейроны не упорядочены, обучается только нейрон-победитель.
2. **Карта Кохонена (SOM)** — нейроны образуют регулярную структуру (например, линейную для одномерного случая), что позволяет сохранять **топологическую близость** кластеров.

**Одномерная сеть Кохонена** — это SOM с линейным расположением нейронов. После обучения нейроны, соответствующие схожим объектам, оказываются близко друг к другу на этой линии, что облегчает визуализацию и интерпретацию кластеров.

**Ответ на вопрос 3**

**Оптимизация в обучении глубоких моделей. Отличие машинного обучения от чистой оптимизации.**

В **машинном обучении** цель — минимизировать **риск** (ожидаемую функцию потерь на истинном распределении данных), но истинное распределение неизвестно. Поэтому на практике минимизируют **эмпирический риск** — среднюю потерю по обучающей выборке. Это является лишь суррогатной задачей для достижения истинной цели — хорошего обобщения.

**Ключевые отличия от чистой оптимизации:**

1.  **Конечная цель:** В чистой оптимизации минимизация целевой функции \( J(\theta) \) — это и есть конечная цель. В машинном обучении минимизация \( J(\theta) \) (эмпирического риска) — лишь средство для улучшения неизвестной метрики качества \( P \) на тестовых данных.
2.  **Критерии остановки:** Алгоритмы обучения часто останавливаются не в локальном минимуме \( J(\theta) \), а на основе **ранней остановки**, чтобы предотвратить переобучение. Обучение может завершиться, когда градиент суррогатной функции потерь ещё велик, что неприемлемо в чистой оптимизации.
3.  **Суррогатные функции:** Часто оптимизируется не истинная, а **суррогатная функция потерь** (например, перекрёстная энтропия вместо точности классификации), которая лучше ведёт себя с точки зрения оптимизации.
4.  **Стохастичность и мини-пакеты:** Градиент вычисляется не по всей функции стоимости (полному набору данных), а по **мини-пакетам**, что вносит шум, но значительно ускоряет процесс и улучшает обобщение.


# Билет 17

<img width="1097" height="451" alt="image" src="https://github.com/user-attachments/assets/b3d7e8e9-36bf-4e82-bcab-e277d589ea62" />

**Ответ на вопрос 1**

**Оптимальное проектирование и обучение нейронных сетей. Теорема существования.**

В основе оптимального проектирования нейронных сетей лежит **теорема Арнольда–Колмогорова–Хехт-Нильсена**, которая доказывает, что любой непрерывной функции многих переменных \( f(x_1, x_2, ..., x_n) \) можно сколь угодно точно аппроксимировать с помощью двухслойного персептрона с одним скрытым слоем сигмоидных нейронов и конечным числом нейронов. Это означает, что для решения любой задачи аппроксимации достаточно сети с **одним скрытым слоем**. Количество необходимых синаптических связей \( N_w \) оценивается по формуле:

<img width="432" height="65" alt="image" src="https://github.com/user-attachments/assets/6f55c9c8-d47e-4f82-a228-049b0769c81b" />


где:
- \( N_x \) — число нейронов входного слоя,
- \( N_y \) — число нейронов выходного слоя,
- \( Q \) — количество обучающих примеров.

**Практические рекомендации по проектированию персептронов**

На практике, несмотря на теоретическую достаточность одного скрытого слоя, часто используются сети с одним или двумя скрытыми слоями. Количество нейронов в скрытых слоях обычно выбирается в диапазоне от \( N_x / 2 \) до \( 3 N_x \). Строгой теории выбора оптимальной архитектуры не существует, поэтому рекомендуется:
1. Начинать со структуры, предлагаемой нейроимитатором по умолчанию.
2. Если сеть не обучается, изменять количество нейронов или слоёв (увеличивать или уменьшать).
3. Избегать **переобучения** — ситуации, когда сеть хорошо работает на обучающей выборке, но плохо обобщает на тестовых данных. Это происходит при чрезмерном увеличении числа нейронов (гиперразмерность).
4. Обеспечивать **репрезентативность** обучающей выборки: она должна охватывать все возможные ситуации, не содержать противоречий и иметь примерно равное количество примеров для каждого класса.

Точность сети на тестовой выборке обычно составляет 70–90%, что соответствует уровню эксперта-человека. Выбор архитектуры сети также зависит от сложности задачи, объёма данных, доступных вычислительных ресурсов и требуемого быстродействия.

**Ответ на вопрос 2**

**Нейронные сети Кохонена. Обучение сети Кохонена. Пример обучения.**

**Обучение сети Кохонена** — это процесс **обучения без учителя**, в результате которого веса нейронов настраиваются так, чтобы они становились **центрами кластеров** для похожих входных векторов.

**Основные этапы алгоритма обучения:**

1. **Инициализация.** Веса всех нейронов Kохонена инициализируются малыми случайными значениями и затем нормализуются.

2. **Предъявление входного вектора.** На вход сети подаётся нормированный вектор \( X(t) \).

3. **Определение нейрона-победителя.** Вычисляются расстояния от входного вектора до векторов весов всех нейронов (например, по Евклидовой метрике). Нейрон, вектор весов которого ближе всего к \( X(t) \), объявляется победителем (принцип **Winner Takes All**).

4. **Коррекция весов.**
   *   Для **слоя конкурирующих нейронов** (Kohonen layer) подстраиваются веса только победившего нейрона:
<img width="323" height="46" alt="image" src="https://github.com/user-attachments/assets/0fdf32c2-0bf2-452a-aecf-17148f29988b" />

   *   Для **самоорганизующейся карты (SOM)** подстраиваются веса и победителя, и его соседей в топологической решётке:
 <img width="374" height="46" alt="image" src="https://github.com/user-attachments/assets/52ebefa2-5b2d-4efa-a62f-7003897a419d" />

      где \( \eta \) — коэффициент скорости обучения, \( g(i,j) \) — функция соседства (например, Гауссова), определяющая степень влияния на соседние нейроны.

5. **Циклическое повторение.** Шаги 2-4 повторяются для всех векторов обучающей выборки (эпоха). Коэффициент обучения \( \eta \) и радиус соседства постепенно уменьшаются от эпохи к эпохе.

**Пример обучения** (по лекции):
Даны 4 входных вектора:  
\( X_1 = [1, 1, 0, 0] \), \( X_2 = [0, 0, 0, 1] \), \( X_3 = [1, 1, 0, 0] \), \( X_4 = [0, 0, 1, 1] \).  
Сеть имеет 2 нейрона со случайными начальными весами:  
\( W_1^T = [0.2, 0.6, 0.5, 0.9] \), \( W_2^T = [0.8, 0.4, 0.7, 0.3] \).  
Коэффициент обучения \( \eta = 0.6 \).

*   **Шаг 1:** Подаётся \( X_1 \). Расстояние до \( W_2 \) меньше → победитель — второй нейрон. Его веса корректируются, приближаясь к \( X_1 \).
*   **Шаг 2:** Подаётся \( X_2 \). Победитель — первый нейрон. Его веса корректируются в сторону \( X_2 \).

Процесс повторяется для всех векторов в нескольких эпохах. В конце обучения веса стремятся к предельным значениям:  
\( W_1^T \) → центр кластера для векторов \( X_2, X_4 \),  
\( W_2^T \) → центр кластера для векторов \( X_1, X_3 \).  
Таким образом, сеть успешно разделила входные данные на два кластера.



# Билет 18

<img width="1096" height="403" alt="image" src="https://github.com/user-attachments/assets/9d07c12c-c953-468f-b9a8-3da421d50020" />

**Ответ на вопрос 1**

**Стохастические методы обучения нейронных сетей. Использование обучения.**

**Стохастические методы обучения** используются для настройки весов нейронной сети с помощью псевдослучайных изменений, сохраняя только те изменения, которые улучшают целевую функцию. Они позволяют избегать локальных минимумов за счёт случайных шагов, которые могут временно ухудшать функцию, но дают возможность выйти из локального оптимума.  

Основной принцип использования обучения включает:
1. Случайный выбор веса и его небольшая случайная коррекция.
2. Вычисление выходов сети и сравнение с желаемыми значениями через целевую функцию.
3. Сохранение изменения, если оно улучшает целевую функцию, или возврат к предыдущему значению в противном случае.
4. Постепенное уменьшение размера случайных шагов для стабилизации сети в глобальном минимуме.

Эти методы применяются как для обучения сети, так и для получения выходов от обученной сети, обеспечивая более надёжное обучение по сравнению с детерминистскими методами.

**Ответ на вопрос 2**

**Нейронные сети Кохонена. Контекстные карты. Пример контекстной карты.**

**Контекстные (семантические) карты** — это результат применения самоорганизующейся карты Кохонена (SOM) для **визуализации и анализа структуры данных**, где нейроны карты маркируются в соответствии с содержательными метками объектов, которые их сильнее всего активируют.

**Суть метода:**
1.  Обучается стандартная SOM (например, двумерная решётка нейронов).
2.  После обучения **каждому нейрону** присваивается **метка класса** или имя объекта из тестовой выборки, на который данный нейрон даёт максимальный отклик.
3.  Нейроны с одинаковыми или близкими метками формируют на карте **когерентные области** (кластеры).

**Свойства контекстной карты:**
*   Сохраняет **топологическое упорядочивание** — семантически близкие объекты (например, животные одного семейства) активируют нейроны, расположенные рядом на карте.
*   Позволяет **наглядно выявлять скрытые взаимосвязи и кластеры** в данных.

**Пример контекстной карты** (из лекции):
Рассматривалось множество животных, описываемых 13 бинарными признаками (наличие/отсутствие свойства).
*   После обучения SOM каждому нейрону было присвоено название животного, на которое он реагировал сильнее всего.
*   На полученной карте чётко выделились три обособленных кластера:
    1.  **Птицы.**
    2.  **Травоядные/мирные животные.**
    3.  **Хищники.**
*   Таким образом, контекстная карта наглядно отобразила **«родственные связи»** между 16 различными животными, сгруппировав их по семантической близости, хотя изначально в данных не было задано никаких классов.

**Применение:** Контекстные карты используются для решения задач классификации, исследования данных (data exploration), дистанционного зондирования и извлечения скрытых закономерностей (data mining).

**Ответ на вопрос 3**

**Оптимизация в обучении глубоких моделей. Пакетные и мини-пакетные алгоритмы.**

Целевая функция в машинном обучении обычно представлена в виде суммы потерь на отдельных обучающих примерах. В зависимости от того, по какому количеству примеров вычисляется градиент для одного обновления параметров, различают:

1.  **Пакетные (или полнопакетные) алгоритмы (Batch Gradient Descent):**
    *   Градиент вычисляется по **всему обучающему набору**.
    *   **Плюсы:** Обеспечивает точное направление убывания функции стоимости (несмещённая оценка градиента). Сходимость стабильна и предсказуема.
    *   **Минусы:** Вычислительно очень затратно для больших наборов данных. Требует всей выборки в памяти. Медленное обновление параметров. Может застревать в плохих локальных минимумах.

2.  **Мини-пакетные алгоритмы (Mini-batch Gradient Descent):**
    *   Градиент оценивается по **небольшой случайной выборке (мини-пакету)** примеров из обучающего набора.
    *   **Плюсы:** Основное преимущество — **компромисс между скоростью и стабильностью.**
        *   **Вычислительная эффективность:** Время на одно обновление не растёт с размером всего набора данных.
        *   **Ускорение сходимости:** Много обновлений за один проход по данным (эпоху).
        *   **Уменьшение дисперсии оценки градиента** по сравнению со стохастическим градиентным спуском (по одному примеру), что делает сходимость более плавной.
        *   Хорошо ложится на параллельные вычисления (GPU).
    *   **Минусы:** Оценка градиента зашумлена. Требуется тщательный подбор размера мини-пакета и скорости обучения.
    *   **Размер мини-пакета** обычно выбирается от 32 до 256 (иногда до 1024 для очень больших моделей). Он ограничен объёмом памяти и оптимальными размерами для аппаратного ускорения.

**Стохастический градиентный спуск (SGD)** можно рассматривать как частный случай мини-пакетного алгоритма с размером пакета, равным 1.

Таким образом, в современном глубоком обучении **мини-пакетный подход (чаще всего через SGD или его адаптивные варианты) является стандартом де-факто**, так как оптимально сочетает скорость, устойчивость и вычислительную эффективность.

# Билет 19

<img width="1098" height="377" alt="image" src="https://github.com/user-attachments/assets/9c6f9cf8-cbfe-4012-8945-0955d5b40d1d" />

**Ответ на вопрос 1**

**Стохастические методы обучения нейронных сетей. Больцмановское обучение.**

**Стохастические методы обучения** основаны на случайных изменениях весов сети с сохранением тех изменений, которые улучшают целевую функцию. Это позволяет избегать локальных минимумов.

**Больцмановское обучение** — это стохастический метод, использующий искусственную температуру \(T\) и распределение Больцмана. Процесс включает:
1. Задание высокой начальной температуры \(T\).
2. Случайное изменение веса и пересчёт целевой функции.
3. Если изменение улучшает функцию, оно сохраняется. Если ухудшает — сохраняется с вероятностью \(P(e) = \exp(-e/kT)\), где \(e\) — изменение функции, \(k\) — постоянная Больцмана.
4. Температура постепенно снижается, что позволяет сети выходить из локальных минимумов и стабилизироваться в глобальном минимуме.

Этот метод аналогичен процессу отжига в металлах и обеспечивает сходимость к оптимальному решению.

**Ответ на вопрос 2**

**Стратегии обучения на основе RBF. Строгая интерполяция с регуляризацией.**

**Стратегии обучения RBF-сети** включают два подхода к определению весов выходного слоя и параметров скрытого слоя. **Строгая интерполяция с регуляризацией** — это продвинутый метод обучения, сочетающий точное воспроизведение обучающих данных (интерполяцию) с предотвращением переобучения.

**1. Строгая интерполяция (без регуляризации):**
*   **Цель**: точно аппроксимировать каждую обучающую пару (xᵢ, yᵢ), чтобы выход сети f(xᵢ) в точности равнялся целевому значению yᵢ.
*   **Условие**: количество нейронов скрытого слоя (центров) m берётся равным количеству обучающих примеров n (m = n). Центрами становятся сами входные векторы: Cᵢ = xᵢ.
*   **Матричное уравнение**: задача сводится к решению системы линейных уравнений:
<img width="99" height="42" alt="image" src="https://github.com/user-attachments/assets/7054c2f0-e4a2-42c0-b0bf-bcc6ab19bb4b" />

    где:
    *   \(\Phi\) — квадратная матрица (n x n), элемент которой \(\phi_{ij} = \varphi(\|x_i - x_j\|)\) — значение RBF-функции для расстояния между i-м и j-м обучающими примерами.
    *   \(W\) — вектор искомых весов выходного слоя (n x 1).
    *   \(Y\) — вектор целевых выходов (n x 1).
*   **Решение**: если матрица \(\Phi\) невырождена, веса находятся напрямую:
<img width="119" height="33" alt="image" src="https://github.com/user-attachments/assets/f3ed2955-9544-4a43-a564-7036ad133325" />

*   **Недостатки**:
    1.  **Переобучение (overfitting)**: сеть идеально запоминает обучающую выборку, включая шум, и плохо обобщает на новые данные.
    2.  **Вычислительная сложность**: обращение матрицы \(\Phi\) размера n x n требует O(n³) операций, что неприемлемо при больших n.
    3.  **Численная неустойчивость**: матрица \(\Phi\) может быть плохо обусловленной.

**2. Строгая интерполяция с регуляризацией (Regularized Strict Interpolation):**
*   **Цель**: сохранить точность интерполяции, но при этом обеспечить гладкость аппроксимирующей функции и устойчивость к шуму, предотвратив переобучение.
*   **Идея**: вводится **параметр регуляризации (λ ≥ 0)**, который штрафует за слишком большие (неустойчивые) значения весов W. Задача превращается в минимизацию **регуляризованного функционала ошибки (Тихоновская регуляризация)**:
<img width="295" height="76" alt="image" src="https://github.com/user-attachments/assets/42f6f912-6589-4dc1-b6c8-c1a25ccc6011" />

    где \(\|W\|^2 = W^T W\) — норма вектора весов (штраф за сложность модели).
*   **Решение**: минимизация \(E(W)\) приводит к **регуляризованному псевдообращению**. Оптимальные веса находятся по формуле:
<img width="218" height="39" alt="image" src="https://github.com/user-attachments/assets/c859d924-bc97-499b-9658-8c7c86f7bd3b" />

    где \(I\) — единичная матрица.
*   **Эффект регуляризации**:
    *   **λ = 0**: возвращаемся к строгой интерполяции (риск переобучения).
    *   **λ > 0**: решение становится более устойчивым, веса уменьшаются, функция сглаживается. Увеличивается обобщающая способность (bias-variance tradeoff).
    *   **λ → ∞**: веса стремятся к нулю, модель становится слишком простой (недообучение).

**Преимущества подхода с регуляризацией:**
*   **Контроль переобучения**: параметр λ позволяет управлять компромиссом между точностью на обучающих данных и обобщением.
*   **Улучшение численной устойчивости**: добавление λI улучшает обусловленность матрицы \((\Phi^T \Phi + \lambda I)\), делая её обратимой даже при плохой обусловленности \(\Phi\).
*   **Работа с зашумленными данными**: регуляризация эффективно подавляет влияние шума.

**Вывод**: **Строгая интерполяция с регуляризацией** — это ключевая стратегия обучения RBF-сетей, которая преодолевает главный недостаток чистой интерполяции — переобучение. Она позволяет строить модели, которые точно аппроксимируют данные, оставаясь устойчивыми и обладающими хорошей обобщающей способностью. Этот подход лежит в основе многих практических реализаций RBF-сетей для задач регрессии и классификации, где важна как точность, так и надёжность модели.

**Ответ на вопрос 3**

**Оптимизация в обучении глубоких моделей. Проблемы оптимизации нейронных сетей.**

Обучение глубоких нейронных сетей сопряжено с рядом сложных проблем оптимизации, которые не характерны для традиционной выпуклой оптимизации. Основные из них:

1.  **Плохая обусловленность матрицы Гессе (Hessian):**
    *   Собственные значения матрицы вторых производных сильно различаются.
    *   Это приводит к тому, что градиентный спуск ведёт себя неэффективно: в одном направлении (с большой кривизной) шаг должен быть маленьким, чтобы не "перепрыгнуть" минимум, а в другом (с малой кривизной) — большим для быстрого продвижения. Выбрать единую скорость обучения для всех направлений трудно.

2.  **Локальные минимумы:**
    *   В невыпуклых функциях потерь нейронных сетей существует множество локальных минимумов.
    *   Однако на практике часто оказывается, что многие из них имеют значение функции потерь, близкое к глобальному минимуму, поэтому эта проблема может быть менее критичной.

3.  **Седловые точки и плато:**
    *   **Седловые точки** — это точки, где градиент равен нулю, но они не являются ни минимумом, ни максимумом (матрица Гессе имеет как положительные, так и отрицательные собственные значения). В многомерных пространствах они встречаются чаще, чем локальные минимумы, и могут сильно замедлять обучение.
    *   **Плато (плоские области)** — обширные регионы с почти постоянным значением функции и близким к нулю градиентом, где обучение практически останавливается.

4.  **Резко растущие градиенты (утесы):**
    *   В сетях с большим числом слоёв (особенно в рекуррентных) из-за перемножения многих больших весов могут возникать очень крутые участки поверхности потерь ("утесы").
    *   На таком "утесе" даже небольшой шаг градиентного спуска приводит к огромному изменению параметров и функции потерь (взрыву градиента). Для борьбы с этим используется **отсечение градиента (gradient clipping)**.

5.  **Неточные градиенты:**
    *   На практике почти всегда используется **зашумлённая оценка градиента** (по мини-пакету), а не точный градиент по всему набору данных. Это вносит дисперсию, но часто помогает избежать локальных минимумов.

6.  **Несоответствие локальной и глобальной структуры:**
    *   Направление наискорейшего локального спуска может не вести к области глобального минимума, заставляя алгоритм делать длинные обходные пути (например, вокруг "горы" на поверхности потерь), что значительно увеличивает время обучения.

Для решения этих проблем разработаны специальные алгоритмы: **импульс, адаптивные скорости обучения (AdaGrad, RMSProp, Adam), методы второго порядка (сопряжённые градиенты, L-BFGS)**, а также техники вроде **пакетной нормировки**, которая стабилизирует распределение входов для слоёв.

# Билет 20

<img width="1095" height="430" alt="image" src="https://github.com/user-attachments/assets/2a5cc378-06d7-4020-a9f4-68f95f15dcc9" />

**Ответ на вопрос 1**

**Стохастические методы обучения нейронных сетей. Сигмоидальные сети доверия. Обучение в сигмоидальных сетях доверия.**

**Сигмоидальные сети доверия** — это стохастические нейронные сети с ациклической архитектурой, использующие сигмоидальную функцию для вычисления вероятности активации нейрона. Они являются упрощённым аналогом машины Больцмана, но не требуют симметричных связей и отрицательной фазы обучения.

**Обучение в сигмоидальных сетях доверия** выполняется следующим образом:
1. Веса инициализируются случайными значениями.
2. Видимые нейроны фиксируются в состояниях, соответствующих обучающим примерам.
3. Для каждого примера выполняется **квантование Гиббса** при температуре \(T = 1\) для достижения условного распределения состояний.
4. Вычисляется средняя корреляция между нейронами:
<img width="445" height="71" alt="image" src="https://github.com/user-attachments/assets/12996f72-f07f-4754-9268-1c3b8f071693" />

где \(\varphi(v) = \frac{1}{1 + \exp(-v)}\) — сигмоидальная функция.
5. Веса корректируются по правилу:
<img width="141" height="42" alt="image" src="https://github.com/user-attachments/assets/fcdca002-3a85-4c7e-9072-e6ddf331226d" />

где \(\eta\) — скорость обучения.

Обучение происходит **в одну фазу**, без необходимости в отрицательном сэмплировании, что делает его значительно быстрее, чем обучение машины Больцмана. Сеть способна моделировать распределения вероятностей и выполнять дополнение образов.

**Ответ на вопрос 2**

**Стратегии обучения на основе RBF. Применение метода обратного распространения ошибки для радиально-базисных сетей.**

**Стратегии обучения RBF-сети** традиционно делятся на два этапа: 1) настройка параметров скрытого (радиально-базисного) слоя, 2) расчёт весов выходного (линейного) слоя. Однако для достижения максимальной точности все параметры сети (центры \( C_i \), ширины \( \sigma_i \) и веса выходного слоя \( W \)) можно обучать совместно с помощью градиентных методов, в частности, **метода обратного распространения ошибки (Backpropagation)**.

**Применение Backpropagation для RBF-сетей** — это стратегия **обучения с учителем**, при которой подстраиваются все параметры сети, что часто позволяет достичь более высокой точности, чем классические двухэтапные методы.

**Алгоритм обучения RBF-сети с помощью Backpropagation:**

1.  **Инициализация параметров**:
    *   Центры \( C_i \) — например, с помощью алгоритма K-средних или случайным образом.
    *   Ширины \( \sigma_i \) — эвристически (например, на основе расстояний между центрами).
    *   Веса выходного слоя \( W \) — случайными малыми значениями.

2.  **Прямой проход (Forward Pass)**:
    Для каждого входного вектора \( X \):
<img width="520" height="254" alt="image" src="https://github.com/user-attachments/assets/b45e33e3-55ad-4120-be4f-86df0924f3f3" />


3.  **Вычисление ошибки**:
    Используется целевое значение \( y_{target} \), чаще всего — **среднеквадратичная ошибка (MSE)**:
<img width="197" height="54" alt="image" src="https://github.com/user-attachments/assets/31ad73e6-9503-49a4-b8ca-5faa42017e3f" />


4.  **Обратный проход и обновление параметров (Backward Pass)**:
    Градиенты ошибки распространяются назад по сети, и все параметры корректируются.

    <img width="521" height="492" alt="image" src="https://github.com/user-attachments/assets/09d6fceb-ae45-4b88-a37a-21c8424f881b" />

    где \( \eta \) — скорость обучения.

5.  **Итерация**: Шаги 2-4 повторяются для всех обучающих примеров (эпоха) до достижения заданной точности или числа эпох.

**Преимущества использования Backpropagation для RBF-сетей:**
*   **Повышение точности**: Совместная тонкая настройка всех параметров позволяет сети лучше адаптироваться к специфике данных.
*   **Автоматизация**: Отпадает необходимость в раздельных алгоритмах для центров и весов.
*   **Гибкость**: Может использоваться с различными функциями ошибки и активации.

**Недостатки и сложности:**
*   **Вычислительная сложность**: Обучение становится значительно медленнее, особенно для больших сетей.
*   **Риск переобучения**: Необходимо использовать методы регуляризации (например, early stopping, weight decay).
*   **Проблемы сходимости**: Как и в MLP, существует риск попадания в локальные минимумы и зависимость от начальной инициализации.
*   **Чувствительность параметров**: Требует тщательного подбора скорости обучения и других гиперпараметров.

**Вывод**: **Применение метода обратного распространения ошибки** для обучения RBF-сетей представляет собой продвинутую стратегию, которая стирает границу между RBF-сетями и многослойными перцептронами. Этот подход позволяет создавать высокоточные модели, но требует больше вычислительных ресурсов и осторожности в настройке. Он особенно оправдан в задачах, где критически важна максимальная точность аппроксимации, а классические двухэтапные методы не обеспечивают необходимого качества.

**Ответ на вопрос 3**

**Оптимизация в обучении глубоких моделей. Проблемы оптимизации нейронных сетей.**

Обучение глубоких нейронных сетей сопряжено с рядом сложных проблем оптимизации, которые не характерны для традиционной выпуклой оптимизации. Основные из них:

1.  **Плохая обусловленность матрицы Гессе (Hessian):**
    *   Собственные значения матрицы вторых производных сильно различаются.
    *   Это приводит к тому, что градиентный спуск ведёт себя неэффективно: в одном направлении (с большой кривизной) шаг должен быть маленьким, чтобы не "перепрыгнуть" минимум, а в другом (с малой кривизной) — большим для быстрого продвижения. Выбрать единую скорость обучения для всех направлений трудно.

2.  **Локальные минимумы:**
    *   В невыпуклых функциях потерь нейронных сетей существует множество локальных минимумов.
    *   Однако на практике часто оказывается, что многие из них имеют значение функции потерь, близкое к глобальному минимуму, поэтому эта проблема может быть менее критичной.

3.  **Седловые точки и плато:**
    *   **Седловые точки** — это точки, где градиент равен нулю, но они не являются ни минимумом, ни максимумом (матрица Гессе имеет как положительные, так и отрицательные собственные значения). В многомерных пространствах они встречаются чаще, чем локальные минимумы, и могут сильно замедлять обучение.
    *   **Плато (плоские области)** — обширные регионы с почти постоянным значением функции и близким к нулю градиентом, где обучение практически останавливается.

4.  **Резко растущие градиенты (утесы):**
    *   В сетях с большим числом слоёв (особенно в рекуррентных) из-за перемножения многих больших весов могут возникать очень крутые участки поверхности потерь ("утесы").
    *   На таком "утесе" даже небольшой шаг градиентного спуска приводит к огромному изменению параметров и функции потерь (взрыву градиента). Для борьбы с этим используется **отсечение градиента (gradient clipping)**.

5.  **Неточные градиенты:**
    *   На практике почти всегда используется **зашумлённая оценка градиента** (по мини-пакету), а не точный градиент по всему набору данных. Это вносит дисперсию, но часто помогает избежать локальных минимумов.

6.  **Несоответствие локальной и глобальной структуры:**
    *   Направление наискорейшего локального спуска может не вести к области глобального минимума, заставляя алгоритм делать длинные обходные пути (например, вокруг "горы" на поверхности потерь), что значительно увеличивает время обучения.

Для решения этих проблем разработаны специальные алгоритмы: **импульс, адаптивные скорости обучения (AdaGrad, RMSProp, Adam), методы второго порядка (сопряжённые градиенты, L-BFGS)**, а также техники вроде **пакетной нормировки**, которая стабилизирует распределение входов для слоёв.

# Билет 21

<img width="1097" height="456" alt="image" src="https://github.com/user-attachments/assets/8245dd20-ce4c-4af7-951f-3295e1f8ffd3" />

**Ответ на вопрос 1**

**Стохастические методы обучения нейронных сетей. Обучение Коши. Метод искусственной теплоёмкости.**

**Обучение Коши** — это стохастический метод, в котором распределение Больцмана заменяется на **распределение Коши**, имеющее более длинные «хвосты». Это увеличивает вероятность больших случайных шагов, что ускоряет выход из локальных минимумов.

**Формула распределения Коши:**
<img width="169" height="59" alt="image" src="https://github.com/user-attachments/assets/df67065f-4fc6-4f0f-b75e-b1b51816258d" />

где \(x\) — величина шага, \(T(t)\) — искусственная температура.

**Изменение температуры** происходит быстрее, чем в Больцмановском обучении:
<img width="122" height="55" alt="image" src="https://github.com/user-attachments/assets/114dcb85-83cb-41a8-a066-c4e1fad06156" />

Это позволяет уменьшать температуру обратно пропорционально линейному времени, а не логарифмически, что значительно сокращает время обучения.

**Метод искусственной теплоёмкости** в обучении Коши позволяет использовать более высокую скорость снижения температуры, так как распределение Коши имеет бесконечную дисперсию. Это даёт системе возможность делать большие шаги на ранних этапах и постепенно уменьшать их, эффективно достигая глобального минимума без застревания в локальных оптимумах.

Таким образом, обучение Коши сочетает стохастическую природу с ускоренным охлаждением, что делает его более быстрым по сравнению с Больцмановским обучением.

**Ответ на вопрос 2**

**Сети на основе радиальных базисных функций. RBF-функции. Расчет параметров радиальной нейронной сети.**

**Сети на основе радиальных базисных функций (RBF-сети)** — это трёхслойные нейронные сети прямого распространения, предназначенные для решения задач аппроксимации функций, классификации и прогнозирования. Их архитектура состоит из:
1.  **Входного слоя** (сенсорные элементы, распределяющие входные сигналы).
2.  **Единственного скрытого (радиально-базисного) слоя**, выполняющего **нелинейное преобразование** входного пространства в пространство более высокой размерности.
3.  **Выходного (линейного) слоя**, который вычисляет взвешенную сумму выходов скрытого слоя.

**RBF-функции (радиальные базисные функции)** — это функции активации нейронов скрытого слоя. Их ключевая особенность: выход зависит только от **расстояния** (евклидовой нормы) между входным вектором \( X \) и **центром** функции \( C_i \), а не от направления.

**Наиболее распространённая RBF-функция — гауссова (Gaussian):**
<img width="251" height="59" alt="image" src="https://github.com/user-attachments/assets/7af2449b-b0cc-4a89-85c8-5777a502e816" />

*   \( X \) — входной вектор.
*   \( C_i \) — **центр** i-го RBF-нейрона (вектор той же размерности, что и \( X \)).
*   \( \sigma_i \) — **параметр ширины (разброса)**, определяющий радиус влияния функции. Чем больше \( \sigma_i \), тем более плавной и широкой является функция.
*   \( \|X - C_i\| \) — евклидово расстояние между \( X \) и \( C_i \).

Функция достигает максимума (1) при \( X = C_i \) и монотонно убывает до 0 по мере удаления от центра.

**Расчет параметров радиальной нейронной сети** проводится, как правило, в **два этапа**:

**1. Расчет параметров скрытого (RBF) слоя: центров \( C_i \) и ширин \( \sigma_i \).**
   *   **Метод 1: Случайный выбор фиксированных центров.** Центры случайно выбираются из обучающей выборки, \( \sigma \) задаётся глобально (например, как среднее расстояние между центрами). Простой, но неэффективный метод.
   *   **Метод 2: Самоорганизация (обучение без учителя).** Основной подход — алгоритм **K-средних (K-means)**.
        *   **Инициализация**: случайный выбор K начальных центров.
        *   **Кластеризация**: каждый обучающий вектор относится к ближайшему центру.
        *   **Адаптация**: центры пересчитываются как среднее векторов своего кластера.
        *   Процесс повторяется до стабилизации.
   *   После определения центров \( C_i \), параметры \( \sigma_i \) рассчитываются на основе расстояний между центрами. Частая эвристика:
 <img width="193" height="67" alt="image" src="https://github.com/user-attachments/assets/33d234fa-eb6c-4734-883f-dc94f3cfffd3" />

        где \( C_j \) — R ближайших соседей центра \( C_i \) (обычно R от 3 до 5). Это обеспечивает плавное перекрытие областей действия функций.

**2. Расчет весов выходного (линейного) слоя \( W \).**
   После фиксации параметров скрытого слоя задача сводится к **линейной регрессии**. Выход сети для входного вектора \( X_k \):
<img width="215" height="73" alt="image" src="https://github.com/user-attachments/assets/b7da956b-de95-4b3c-a7e1-7a8c4d02abab" />

   где \( m \) — число RBF-нейронов, \( w_0 \) — смещение.

   **Цель**: минимизировать суммарную квадратичную ошибку между выходами сети \( y_k \) и целевыми значениями \( d_k \). Решение находится **аналитически** с помощью метода наименьших квадратов:
<img width="166" height="45" alt="image" src="https://github.com/user-attachments/assets/36be442c-8b3c-4c71-8e0b-451b32863841" />

   где:
   *   \( \Phi \) — матрица (N x m), строки которой соответствуют выходам всех RBF-нейронов для каждого из N обучающих примеров.
   *   \( D \) — вектор (N x 1) целевых значений.
   *   \( W \) — вектор (m x 1) искомых весов.

   Для повышения устойчивости и борьбы с переобучением используется **регуляризация (Тихоновская)**:
<img width="204" height="39" alt="image" src="https://github.com/user-attachments/assets/f6a3a2b8-11e8-445b-a8d1-eee70e4cc094" />

   где \( \lambda \) — параметр регуляризации, \( I \) — единичная матрица.

**Вывод**: RBF-сети представляют собой мощный инструмент для нелинейного моделирования данных. Их эффективность основана на двух ключевых идеях: 1) **нелинейное преобразование входов с помощью локализованных RBF-функций** и 2) **линейная комбинация их выходов**. Процесс обучения разделён на логические этапы: настройка центров и ширин (часто без учителя) и последующий аналитический расчёт весов выходного слоя (с учителем), что делает обучение относительно быстрым и прозрачным.

**Ответ на вопрос 3**

**Адаптивные резонансные нейронные сети (Adaptive Resonance Theory - ART). Структура нейронной сети АРТ. Взаимодействие слоев распознавания и сравнения.**

Адаптивные резностические нейронные сети (ART) — это класс нейронных сетей, предназначенных для **неконтролируемого и контролируемого обучения распознаванию образов** с возможностью **инкрементального обучения** без потери ранее изученных знаний (решение проблемы "катастрофического забывания").

**Базовая структура сети ART-1 (для бинарных входов):**
Состоит из двух основных полносвязных слоёв:

1.  **Слой сравнения (F1):** Принимает входной вектор. Его нейроны соответствуют компонентам входного сигнала.
2.  **Слой распознавания (F2):** Содержит нейроны-категории (прототипы). Каждый нейрон представляет один кластер или класс.

**Взаимодействие слоев распознавания и сравнения:**
Процесс является **итеративным циклом "сравнение-распознавание"**:

1.  **Распознавание:** Входной вектор подается на слой F1 и передается на слой F2. Нейрон F2 с наибольшей активацией (наиболее похожий прототип) выбирается как **кандидат**.
2.  **Обратная связь и сравнение:** Выбранный нейрон F2 посылает сигнал обратно на слой F1 по **вектору ожидания** (образцу-прототипу). На F1 происходит сравнение этого прототипа с исходным входом.
3.  **Критерий сходства (бдительности):** Рассчитывается степень совпадения. Если сходство превышает заданный **порог бдительности (vigilance parameter)**, происходит **резонанс** — вход признаётся принадлежащим выбранной категории, и её веса адаптируются, чтобы учесть новый пример.
4.  **Сброс (Reset):** Если сходство ниже порога бдительности, текущий нейрон F2 **тормозится** на время обработки данного входа, и активируется следующий наиболее подходящий кандидат. Если ни одна существующая категория не подходит, создается **новая категория** (новый нейрон в F2).

Таким образом, **взаимодействие происходит через двунаправленные связи**: восходящие (от F1 к F2 для выбора категории) и нисходящие (от F2 к F1 для проверки сходства). Это позволяет сети динамически формировать категории, сохраняя стабильность ранее изученных прототипов и пластичность для изучения нового.

# Билет 22

<img width="1094" height="511" alt="image" src="https://github.com/user-attachments/assets/59c2da81-086d-4dcd-b19b-543003a0985f" />

**Ответ на вопрос 1**

**Стохастические методы обучения нейронных сетей. Обратное распространение и обучение Коши. Трудности, связанные с обратным распространением. Трудности с алгоритмом обучения Коши.**

**Обратное распространение и обучение Коши** могут комбинироваться для улучшения сходимости. Коррекция весов вычисляется как сумма:
- направленной компоненты (обратное распространение),
- случайной компоненты (распределение Коши).

Это позволяет системе быстрее находить глобальный минимум, используя преимущества обоих методов.

**Трудности обратного распространения:**
1. **Сходимость** — доказана только для бесконечно малых шагов, что неприменимо на практике. При конечных шагах сходимость не гарантирована, время обучения велико и непредсказуемо.
2. **Локальные минимумы** — алгоритм застревает в локальных оптимумах, которые могут быть неприемлемыми. Для поиска глобального минимума требуется перезапуск с новыми начальными весами без гарантии успеха.
3. **Паралич сети** — возникает, когда веса становятся слишком большими, выходы нейронов насыщаются, их производные стремятся к нулю, и обучение практически останавливается.

**Трудности с алгоритмом обучения Коши:**
1. **Время обучения** — хотя метод Коши быстрее Больцмановского обучения, он может всё ещё быть в 100 раз медленнее обратного распространения.
2. **Сетевой паралич** — из-за длинных «хвостов» распределения Коши возможны очень большие изменения весов, приводящие к насыщению нейронов и параличу сети.
3. **Неограниченные изменения весов** — бесконечная дисперсия распределения Коши может вызывать нежелательные большие коррекции, даже если они ухудшают целевую функцию, что дестабилизирует обучение.

Оба метода имеют свои недостатки, но их комбинация позволяет частично компенсировать эти проблемы.

**Ответ на вопрос 2**

**Сети на основе радиальных базисных функций. Архитектура RBF-сети. Теорема Ковера о разделимости множеств.**

**Сети на основе радиальных базисных функций (RBF-сети)** — это специальный класс нейронных сетей прямого распространения, предназначенных для решения задач аппроксимации функций, классификации и прогнозирования. Их работа основана на идее **нелинейного преобразования входного пространства в пространство более высокой размерности**, где задача становится линейно разделимой.

**Архитектура RBF-сети** состоит из трёх строго последовательных слоёв, каждый из которых выполняет свою уникальную функцию:

1.  **Входной слой (Input Layer)**:
    *   Состоит из **сенсорных (распределительных) элементов**, количество которых равно размерности входного вектора.
    *   **Функция**: не выполняет вычислений, только передаёт входные сигналы на каждый нейрон следующего слоя.

2.  **Скрытый (радиально-базисный) слой (Hidden / RBF Layer)**:
    *   Это **единственный скрытый слой** в сети.
    *   Каждый нейрон этого слоя реализует **радиальную базисную функцию (RBF)**. Чаще всего используется **гауссова функция**:
<img width="256" height="65" alt="image" src="https://github.com/user-attachments/assets/32d52ba8-6890-4484-b7b4-6c64f6c3f686" />

        где:
        *   \(\mathbf{X}\) — входной вектор.
        *   \(\mathbf{C}_i\) — **центр** i-й RBF-функции (вектор той же размерности, что и вход).
        *   \(\sigma_i\) — **параметр ширины (разброса)**, определяющий радиус действия функции.
        *   \(\|\mathbf{X} - \mathbf{C}_i\|\) — евклидово расстояние.
    *   **Функция слоя**: выполняет **нелинейное отображение** входного вектора \(\mathbf{X}\) в новое, обычно **более высокоразмерное пространство** (количество RBF-нейронов \(m\) > размерности входа \(n\)). Выход каждого нейрона максимален, когда вход близок к его центру, и убывает с удалением.

3.  **Выходной (линейный) слой (Output Layer)**:
    *   Состоит из одного или нескольких **линейных нейронов** (сумматоров).
    *   **Функция**: вычисляет **взвешенную сумму** выходов скрытого слоя. Для одного выходного нейрона:
<img width="215" height="67" alt="image" src="https://github.com/user-attachments/assets/22a76c60-39bf-434b-a9cc-f2fec774f32f" />

        где \(w_i\) — весовые коэффициенты, \(w_0\) — смещение (bias).

**Теорема Ковера о разделимости множеств (Cover's Theorem on the Separability of Patterns)** — это фундаментальный теоретический результат, объясняющий принципиальную эффективность RBF-сетей.

*   **Формулировка**: «Сложная задача классификации образов, спроецированная **нелинейно в пространство более высокой размерности**, с большей вероятностью становится **линейно разделимой**, чем в исходном пространстве».

*   **Суть для RBF-сетей**:
    1.  Скрытый слой с RBF-функциями \(\varphi_i(\mathbf{X})\) выполняет роль этого **нелинейного преобразования**.
    2.  Вектор выходов скрытого слоя \(\mathbf{\Phi}(\mathbf{X}) = [\varphi_1(\mathbf{X}), \varphi_2(\mathbf{X}), ..., \varphi_m(\mathbf{X})]^T\) представляет входной образ в новом \(m\)-мерном пространстве.
    3.  **Теорема утверждает**, что если количество RBF-нейронов \(m\) (размерность нового пространства) **достаточно велико**, то практически любое множество образов становится **линейно разделимым** в этом пространстве.
    4.  Следовательно, в преобразованном пространстве для разделения классов достаточно простого **линейного классификатора**, роль которого выполняет выходной слой RBF-сети.

*   **Практическое следствие**: RBF-сеть с достаточно большим скрытым слоем гарантированно может решить задачу классификации, построив всего **два обучаемых слоя** (нелинейный скрытый и линейный выходной), что является её ключевым архитектурным преимуществом перед многослойными перцептронами.

**Вывод**: **Архитектура RBF-сети** с её трёхслойной структурой и **теорема Ковера** образуют мощную концептуальную основу. Сеть использует скрытый слой для «подъёма» данных в пространство, где они становятся линейно разделимыми, что позволяет выходному линейному слою легко построить решающую границу. Это делает RBF-сети особенно эффективными для задач, где данные естественным образом образуют кластеры.

**Ответ на вопрос 3**

**Адаптивные резонансные нейронные сети (ART). Структура нейронной сети АРТ. Структура слоя сравнения. Взаимодействие нейронов слоя распознавания.**

**Структура сети АРТ (базовая модель ART-1):**
Состоит из двух основных полносвязных слоёв: **слоя сравнения F₁** и **слоя распознавания F₂**, соединённых двунаправленными весовыми связями.

---

**1. Структура слоя сравнения (F₁):**
Слой F₁ предназначен для приёма и обработки входного сигнала. Его ключевые особенности:
*   **Функция:** Получает внешний входной вектор и нисходящий вектор "ожидания" (прототип) от выбранного нейрона слоя F₂.
*   **Задача:** Сравнить входной сигнал с прототипом и вычислить степень их сходства.
*   **Реализация:** Часто состоит из трёх полей нейронов:
    1.  Поле для приёма входного сигнала.
    2.  Поле для приёма сигнала обратной связи от F₂.
    3.  Поле, которое активируется только при совпадении этих двух сигналов (резонансе).
*   **Критерий бдительности (vigilance):** На этом слое проверяется, достаточна ли степень совпадения между входом и прототипом. Если сходство ниже порога, активация с F₁ подавляет выбранный нейрон в F₂.

---

**2. Взаимодействие нейронов слоя распознавания (F₂):**
Слой F₂ содержит нейроны-категории, каждый из которых представляет один кластер или класс.
*   **Принцип "победитель-забирает-всё":** Нейроны F₂ конкурируют между собой. Полностью активируется только тот нейрон, который получает **наибольший входной сигнал** (имеет веса, наиболее схожие с текущим входом). Остальные нейроны подавляются.
*   **Функция выбранного нейрона:**
    1.  **Обратная связь:** Активированный нейрон посылает по нисходящим связям свой **вектор-прототип** обратно в слой F₁ для проверки на сходство.
    2.  **Адаптация весов:** Если проверка в F₁ прошла успешно (резонанс), веса этого нейрона адаптируются, чтобы "приблизить" прототип к входному вектору.
    3.  **Сброс (Reset):** Если проверка не прошла, данный нейрон **временно инактивируется** (тормозится) на время обработки данного входного вектора. Конкуренция в F₂ возобновляется среди оставшихся нейронов для выбора нового кандидата.
*   **Создание новой категории:** Если ни одна существующая категория не подошла, активируется новый, ранее не использованный нейрон в F₂, и его веса инициализируются в соответствии с текущим входом.

**Итог:** Взаимодействие в АРТ-сетях представляет собой **цикл обратной связи**: F₁ → F₂ (выбор категории) → F₁ (проверка сходства) → (сброс/адаптация). Это позволяет сети динамически учиться, не разрушая старые знания.

# Билет 23

<img width="1098" height="402" alt="image" src="https://github.com/user-attachments/assets/b544df3b-33f8-41e1-ac2b-0c602a722d53" />

**Ответ на вопрос 1**

**Метод обратного распространения ошибок. Алгоритм обратного распространения ошибки**

**Метод обратного распространения ошибок** — это систематический алгоритм обучения многослойных нейронных сетей, основанный на распространении сигнала ошибки от выходов сети к её входам в направлении, обратном прямому распространению сигналов. Основная идея заключается в получении оценки ошибки для нейронов скрытых слоёв как взвешенной суммы ошибок последующего слоя, что позволяет корректировать весовые коэффициенты связей.

**Алгоритм обратного распространения ошибки** включает следующие шаги:

1. **Подача входного вектора** из обучающей пары на вход сети и вычисление выходного сигнала (прямое распространение).
2. **Вычисление ошибки** на выходе сети (например, квадратичной ошибки \(E = 0.5 \sum (d_j - y_j)^2\)).
<img width="509" height="359" alt="image" src="https://github.com/user-attachments/assets/dece6468-b999-48bd-8ee5-9c6e68bedba9" />

   где \(\alpha\) — коэффициент обучения.
6. **Повторение шагов** для всех обучающих примеров до достижения приемлемого уровня ошибки.

Таким образом, алгоритм сочетает прямое распространение сигнала для вычисления выхода и обратное распространение ошибки для корректировки весов, минимизируя ошибку сети.

**Ответ на вопрос 2**

**Сети встречного распространения. Звезды Гроссберга. Структура сети.**

**Сеть встречного распространения** — это двухслойная гибридная сеть, объединяющая **слой Кохонена** (самоорганизующийся) и **слой Гроссберга** (обучаемый с учителем). Её ключевые компоненты — **входная звезда (инстар)** и **выходная звезда (оутстар)** Гроссберга.

**1. Звезды Гроссберга:**
*   **Инстар (входная звезда):** Это нейрон-детектор. Он имеет множество входов и один выход. Его веса обучаются так, чтобы нейрон активировался (выдавал ненулевой выход) только при предъявлении определённого входного вектора. Обучение может быть как с учителем, так и без.
*   **Оутстар (выходная звезда):** Это нейрон-команда. Он имеет один вход и множество выходов. Его функция — при поступлении входного сигнала выдать на своих выходах определённый вектор, необходимый связанным с ним нейронам. Обучение оутстара по правилу Гроссберга настраивает его веса так, чтобы его выходные сигналы были равны ожидаемым значениям.

**2. Структура сети встречного распространения:**
Сеть состоит из трёх слоёв:
*   **Слой 0 (входной):** Точки разветвления, не выполняющие вычислений.
*   **Слой 1 (Кохонена):** Состоит из нейронов, организованных по принципу самоорганизующейся карты. Каждый нейрон этого слоя соединён со всеми входами (слоем 0) весами \(w_{ij}\), образующими матрицу **W**. Этот слой проводит кластеризацию входных данных по принципу «победитель получает всё».
*   **Слой 2 (Гроссберга):** Состоит из оутстаров (нейронов выходной звезды). Каждый нейрон этого слоя соединён со всеми нейронами слоя Кохонена весами \(v_{ij}\), образующими матрицу **V**. Этот слой формирует итоговый выходной вектор **Y** на основе активности слоя Кохонена.

Таким образом, структура сети представляет собой каскадное соединение самоорганизующегося слоя (для распознавания образов) и ассоциативного слоя (для формирования отклика).

**Ответ на вопрос 3**

**Адаптивные резонансные нейронные сети (ART). Структура нейронной сети АРТ. Теоремы ART. Проблемы и недостатки ART-1.**

**Структура нейронной сети АРТ (базовая ART-1):**
Состоит из двух основных полносвязных слоёв: **слоя сравнения (F₁)** и **слоя распознавания (F₂)**, связанных двунаправленными связями. Ключевой элемент — механизм **обратной связи** и **порог бдительности (vigilance parameter ρ)**, который управляет процессом категоризации.

**Основные теоремы ART (свойства):**
1.  **Теорема о стабильности-пластичности:** Сеть решает дилемму между **пластичностью** (способностью учиться новому) и **стабильностью** (сохранением ранее изученного). Новые знания не стирают старые.
2.  **Теорема о сходимости:** Процесс поиска резонанса (подходящей категории или создания новой) завершается за конечное число шагов.
3.  **Теорема о прямой доступности:** Любой сохранённый образец (прототип) может быть непосредственно извлечён (распознан) при предъявлении достаточно схожего входного вектора.

**Проблемы и недостатки ART-1:**
1.  **Чувствительность к порядку предъявления данных:** Последовательность входных образцов может влиять на конечное разбиение на категории.
2.  **Жёсткость разделения:** Порог бдительности ρ фиксирован. Если он высокий — создаётся много мелких категорий (переподгонка), если низкий — категории становятся слишком грубыми (недообучение).
3.  **Работа только с бинарными данными:** Базовая ART-1 предназначена для двоичных входных векторов, что ограничивает её применение.
4.  **Вычислительная сложность:** В процессе поиска может происходить многократная итерация "распознавание → сравнение → сброс", что требует времени.
5.  **Проблема "забывания" в пределах категории:** При адаптации весов выбранной категории под новый пример, прототип смещается. Крайние примеры, ранее входившие в категорию, могут перестать ей соответствовать ("забывание внутри класса").
6.  **Зависимость от начальных весов:** Инициализация весов может влиять на результат кластеризации.

**Итог:** Несмотря на недостатки, модель ART заложила основы для устойчивого инкрементального обучения. Её модификации (ART-2, ART-3, Fuzzy ART) устраняют многие из этих ограничений.

# Билет 24
<img width="1097" height="404" alt="image" src="https://github.com/user-attachments/assets/bf1e390c-607a-4413-b019-b468b9bc4d3d" />
**Ответ на вопрос 1**

**Метод обратного распространения ошибок. Алгоритм обратного распространения ошибки**

**Метод обратного распространения ошибок** — это систематический алгоритм обучения многослойных нейронных сетей, основанный на распространении сигнала ошибки от выходов сети к её входам в направлении, обратном прямому распространению сигналов. Основная идея заключается в получении оценки ошибки для нейронов скрытых слоёв как взвешенной суммы ошибок последующего слоя, что позволяет корректировать весовые коэффициенты связей.

**Алгоритм обратного распространения ошибки** включает следующие шаги:

1. **Подача входного вектора** из обучающей пары на вход сети и вычисление выходного сигнала (прямое распространение).
2. **Вычисление ошибки** на выходе сети (например, квадратичной ошибки \(E = 0.5 \sum (d_j - y_j)^2\)).
3. **Расчёт ошибки для выходного слоя**:
<img width="194" height="33" alt="image" src="https://github.com/user-attachments/assets/324bf347-39d2-4873-a669-545e12d7be9d" />

4. **Расчёт ошибки для скрытых слоёв**:
<img width="216" height="48" alt="image" src="https://github.com/user-attachments/assets/d4f7a235-2f47-4df9-b721-8e4e26ba71b7" />

5. **Коррекция весов** с использованием дельта-правила:
   - Для связей между скрытым и выходным слоем:
<img width="182" height="34" alt="image" src="https://github.com/user-attachments/assets/a1761f95-0ed9-4be7-b167-7c89045d198c" />

   - Для связей между входным и скрытым слоем:
<img width="174" height="44" alt="image" src="https://github.com/user-attachments/assets/dd3ce690-6e2f-4006-b333-8b96bf13ea45" />

   где \(\alpha\) — коэффициент обучения.
6. **Повторение шагов** для всех обучающих примеров до достижения приемлемого уровня ошибки.

Таким образом, алгоритм сочетает прямое распространение сигнала для вычисления выхода и обратное распространение ошибки для корректировки весов, минимизируя ошибку сети.

**Ответ на вопрос 2**

**Нейронные сети Кохонена. Задачи кластеризации. Структура сети Кохонена. Одномерная сеть Кохонена.**

**Нейронные сети Кохонена** относятся к самоорганизующимся нейронным сетям и предназначены для решения **задачи кластеризации** — разделения множества объектов на группы «похожих» объектов (кластеров) без заранее известных меток классов. В отличие от классификации, кластеры формируются в процессе обучения.

Формально задача кластеризации: дано множество объектов \( I = \{i_1, i_2, ..., i_n\} \), каждый из которых описывается вектором признаков \( x_j \). Требуется построить множество кластеров \( C = \{c_1, c_2, ..., c_g\} \) и отображение \( F : I \to C \), так чтобы объекты внутри кластера были близки по выбранной метрике расстояния \( d(i_j, i_p) \).

**Структура сети Кохонена** включает:
- **Входной слой** (распределяет входные сигналы);
- **Активный слой** (один или несколько нейронов Кохонена).

Сеть является **однослойной**, так как входной слой лишь передает сигналы. Активный слой может быть **одномерным** (линейная структура) или **двумерным** (плоская решетка). В одномерном случае нейроны расположены в одну линию, что соответствует простейшей форме организации и часто используется для базовой кластеризации.

Различают два варианта:
1. **Слой Кохонена** — нейроны не упорядочены, обучается только нейрон-победитель.
2. **Карта Кохонена (SOM)** — нейроны образуют регулярную структуру (например, линейную для одномерного случая), что позволяет сохранять **топологическую близость** кластеров.

**Одномерная сеть Кохонена** — это SOM с линейным расположением нейронов. После обучения нейроны, соответствующие схожим объектам, оказываются близко друг к другу на этой линии, что облегчает визуализацию и интерпретацию кластеров.

**Ответ на вопрос 3**

**Оптимизация в обучении глубоких моделей. Отличие машинного обучения от чистой оптимизации.**

В **машинном обучении** цель — минимизировать **риск** (ожидаемую функцию потерь на истинном распределении данных), но истинное распределение неизвестно. Поэтому на практике минимизируют **эмпирический риск** — среднюю потерю по обучающей выборке. Это является лишь суррогатной задачей для достижения истинной цели — хорошего обобщения.

**Ключевые отличия от чистой оптимизации:**

1.  **Конечная цель:** В чистой оптимизации минимизация целевой функции \( J(\theta) \) — это и есть конечная цель. В машинном обучении минимизация \( J(\theta) \) (эмпирического риска) — лишь средство для улучшения неизвестной метрики качества \( P \) на тестовых данных.
2.  **Критерии остановки:** Алгоритмы обучения часто останавливаются не в локальном минимуме \( J(\theta) \), а на основе **ранней остановки**, чтобы предотвратить переобучение. Обучение может завершиться, когда градиент суррогатной функции потерь ещё велик, что неприемлемо в чистой оптимизации.
3.  **Суррогатные функции:** Часто оптимизируется не истинная, а **суррогатная функция потерь** (например, перекрёстная энтропия вместо точности классификации), которая лучше ведёт себя с точки зрения оптимизации.
4.  **Стохастичность и мини-пакеты:** Градиент вычисляется не по всей функции стоимости (полному набору данных), а по **мини-пакетам**, что вносит шум, но значительно ускоряет процесс и улучшает обобщение.
